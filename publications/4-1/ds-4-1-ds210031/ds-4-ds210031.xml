<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.0 20120330//EN" "JATS-journalpublishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="resource-paper">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">DS</journal-id>
<journal-title-group><journal-title>Data Science</journal-title></journal-title-group>
<issn pub-type="epub">2451-8492</issn><issn pub-type="ppub">2451-8484</issn><issn-l>2451-8484</issn-l>
<publisher>
<publisher-name>IOS Press</publisher-name><publisher-loc>Nieuwe Hemweg 6B, 1013 BG Amsterdam, The Netherlands</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">DS210031</article-id>
<article-id pub-id-type="doi">10.3233/DS-210031</article-id>
<article-categories><subj-group subj-group-type="heading">
<subject>Resource Paper</subject></subj-group></article-categories>
<title-group>
<article-title>WORCS: A workflow for open reproducible code in science</article-title>
</title-group>
<contrib-group content-type="Editor">
<contrib contrib-type="editor">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-1267-0234</contrib-id>
<name><surname>Kuhn</surname><given-names>Tobias</given-names></name>
</contrib>
</contrib-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-0808-5024</contrib-id>
<name><surname>Van Lissa</surname><given-names>Caspar J.</given-names></name><xref ref-type="aff" rid="affa">a</xref><xref ref-type="fn" rid="thanks3">**</xref><xref ref-type="corresp" rid="cor2">*</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-8765-6982</contrib-id>
<name><surname>Brandmaier</surname><given-names>Andreas M.</given-names></name><xref ref-type="aff" rid="affb">b</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-3997-1173</contrib-id>
<name><surname>Brinkman</surname><given-names>Loek</given-names></name><xref ref-type="aff" rid="affc">c</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-1953-5606</contrib-id>
<name><surname>Lamprecht</surname><given-names>Anna-Lena</given-names></name><xref ref-type="aff" rid="affd">d</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-7813-818X</contrib-id>
<name><surname>Peikert</surname><given-names>Aaron</given-names></name><xref ref-type="aff" rid="affe">e</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-1166-1424</contrib-id>
<name><surname>Struiksma</surname><given-names>Marijn E.</given-names></name><xref ref-type="aff" rid="afff">f</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-5023-4601</contrib-id>
<name><surname>Vreede</surname><given-names>Barbara M.I.</given-names></name><xref ref-type="aff" rid="affg">g</xref>
</contrib>
<aff id="affa"><label>a</label>Department of Methodology &amp; Statistics, <institution>Utrecht University</institution>, <country>The Netherlands</country> and <institution>Open Science Community Utrecht</institution>, <country>The Netherlands</country>. E-mail: <email>c.j.vanlissa@uu.nl</email></aff>
<aff id="affb"><label>b</label>Center for Lifespan Psychology, <institution>Max Planck Institute for Human Development</institution>, Berlin, <country>Germany</country> and <institution>Max Planck UCL Centre for Computational Psychiatry and Ageing Research</institution>, Berlin, <country>Germany</country> and London, <country>UK</country>.</aff>
<aff id="affc"><label>c</label><institution>Open Science Community Utrecht</institution>, <country>The Netherlands</country> and University Medical Center, <institution>Utrecht University</institution>, <country>The Netherlands</country>.</aff>
<aff id="affd"><label>d</label><institution>Open Science Community Utrecht</institution>, <country>The Netherlands</country> and Department of Information and Computing Sciences, <institution>Utrecht University</institution>, <country>The Netherlands</country>.</aff>
<aff id="affe"><label>e</label>Center for Lifespan Psychology, <institution>Max Planck Institute for Human Development</institution>, Berlin, <country>Germany</country>.</aff>
<aff id="afff"><label>f</label><institution>Open Science Community Utrecht</institution>, <country>The Netherlands</country> and Utrecht Institute of Linguistics OTS, <institution>Utrecht University</institution>, <country>The Netherlands</country>.</aff>
<aff id="affg"><label>g</label>University Library, <institution>Utrecht University</institution>, <country>The Netherlands</country> and <institution>Netherlands eScience Center</institution>, <country>The Netherlands</country>.</aff>
</contrib-group>
<author-notes>
<corresp id="cor2"><label>*</label>Corresponding author. E-mail: <email>c.j.vanlissa@uu.nl</email>.</corresp><fn id="thanks3"><label>**</label>
<p>All authors of this paper, except the first, are listed in alphabetical order. Author contributions are detailed in the document ’authors.csv’ on the project repository, at <uri>https://github.com/cjvanlissa/worcs</uri>.</p></fn>
</author-notes>
<pub-date date-type="preprint" publication-format="electronic"><day>19</day><month>2</month><year>2021</year></pub-date><pub-date date-type="pub" publication-format="electronic"><day>21</day><month>5</month><year>2021</year></pub-date><pub-date date-type="collection" publication-format="electronic"><year>2021</year></pub-date><volume>4</volume><issue>1</issue><fpage>29</fpage><lpage>49</lpage><history><date date-type="received"><day>25</day><month>09</month><year>2020</year></date><date date-type="accepted"><day>11</day><month>12</month><year>2020</year></date></history>
<permissions><copyright-statement>© 2021 – The authors. Published by IOS Press.</copyright-statement><copyright-year>2021</copyright-year>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/" license-type="open-access" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution (CC BY 4.0) License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p></license></permissions>
<abstract>
<p>Adopting open science principles can be challenging, requiring conceptual education and training in the use of new tools. This paper introduces the Workflow for Open Reproducible Code in Science (WORCS): A step-by-step procedure that researchers can follow to make a research project open and reproducible. This workflow intends to lower the threshold for adoption of open science principles. It is based on established best practices, and can be used either in parallel to, or in absence of, top-down requirements by journals, institutions, and funding bodies. To facilitate widespread adoption, the WORCS principles have been implemented in the R package <monospace>worcs</monospace>, which offers an RStudio project template and utility functions for specific workflow steps. This paper introduces the conceptual workflow, discusses how it meets different standards for open science, and addresses the functionality provided by the <monospace>R</monospace> implementation, <monospace>worcs</monospace>. This paper is primarily targeted towards scholars conducting research projects in R, conducting research that involves academic prose, analysis code, and tabular data. However, the workflow is flexible enough to accommodate other scenarios, and offers a starting point for customized solutions. The source code for the <monospace>R</monospace> package and manuscript, and a list of <ext-link ext-link-type="uri" xlink:href="https://github.com/cjvanlissa/worcs/tree/master#adoption-of-worcs-by-users">examplesof WORCS projects</ext-link>, are available at <uri>https://github.com/cjvanlissa/worcs</uri>.</p>
</abstract>
<kwd-group>
<label>Keywords</label>
<kwd>Open science</kwd>
<kwd>reproducibility</kwd>
<kwd>r</kwd>
<kwd>dynamic document generation</kwd>
<kwd>version control</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="x1-1000-1">
<label>1.</label>
<title>Introduction</title>
<p>Academia is arguably past the tipping point of a paradigm shift towards open science. Support for this transition was first motivated by several highly publicized cases of scientific fraud (Levelt et al. [<xref ref-type="bibr" rid="ref020">20</xref>]), increasing awareness of questionable research practices (John et al. [<xref ref-type="bibr" rid="ref016">16</xref>]), and the replication crisis (Shrout and Rodgers [<xref ref-type="bibr" rid="ref036">36</xref>]). However, open science should not be seen as a cure (or punishment) for this crisis. As the late dr. Jonathan Tennant put it: “Open science is just good science” (Tennant [<xref ref-type="bibr" rid="ref039">39</xref>]). Open science creates opportunities for researchers to more easily conduct reliable, cumulative, and collaborative science (Adolph et al. [<xref ref-type="bibr" rid="ref003">3</xref>]; Nosek and Bar-Anan [<xref ref-type="bibr" rid="ref024">24</xref>]). Open science also promotes inclusivity, because it removes barriers for participation. Capitalizing on these advances has the potential to accelerate scientific progress (see also Coyne [<xref ref-type="bibr" rid="ref011">11</xref>]), as has been aptly demonstrated by the role of open science in the response to the coronavirus pandemic (Sondervan et al. [<xref ref-type="bibr" rid="ref037">37</xref>]).</p>
<p>Many researchers are motivated to adopt current best practices for open science and enjoy these benefits. And yet, the question of how to get started can be daunting. Making the transition requires researchers to become knowledgeable about different open science challenges and solutions, and to become proficient with new and unfamiliar tools. This paper is designed to ease that transition by presenting a simple workflow, based on established best practices, that meets most requirements open science: The <italic>Workflow for Open Reproducible Code in Science</italic> (WORCS).</p>
<p>This paper introduces the conceptual workflow (referred to in upper case, “WORCS”), and discusses its underlying principles and how it meets different standards for open science. The principles underlying this workflow are universal and largely platform independent. We also present a software implementation of WORCS for <monospace>R</monospace> users (R Core Team [<xref ref-type="bibr" rid="ref031">31</xref>]): The <monospace>R</monospace> package <monospace>worcs</monospace> (referred to in monospace font, Van Lissa et al. [<xref ref-type="bibr" rid="ref041">41</xref>]). This package offers a project template for RStudio (RStudio Team [<xref ref-type="bibr" rid="ref035">35</xref>]), and several convenience functions to automate specific workflow steps. This paper is most relevant for scholars using R to conduct research that involves academic prose, analysis code, and tabular data. For other readers, it can serve as a primer on open science workflows, and provide a sensible starting point for a customized solution.</p>
<p>The WORCS workflow constitutes a step-by-step procedure that researchers can follow to make a research project open and reproducible. These steps are elaborated in greater detail below. See Fig. <xref rid="x1-1001-1">1</xref> for a flowchart that highlights important steps in different stages of the research process. WORCS is compatible with open science requirements already implemented by journals and institutions, and will help fulfill them. It can also be used by individual authors to produce work in accordance with best practices in the absence of top-down support or guidelines (i.e., “grass roots” open science).</p>
<fig id="x1-1001-1">
<label>Fig. 1.</label>
<caption>
<p>Schematic illustration of important steps in different stages of the WORCS procedure.</p>
</caption>
<graphic xlink:href="ds-4-ds210031-g001.jpg"/>
</fig>
</sec>
<sec id="x1-2000-2">
<label>2.</label>
<title>Defining open science practices</title>
<p>Although open science is advocated by many, it does not have a unitary definition. Throughout this paper, we adhere to the definition of open science as “the practice of science in such a way that others can collaborate and contribute, where research data, lab notes and other research processes are freely available, under terms that enable reuse, redistribution and reproduction of the research and its underlying data and methods” (the <ext-link ext-link-type="uri" xlink:href="https://www.fosteropenscience.eu/foster-taxonomy/open-science-definition">FOSTER Open Science Definition</ext-link>, as discussed in Bezjak et al. [<xref ref-type="bibr" rid="ref008">8</xref>]). In this context, the term “science” refers to all scholarly disciplines. We further define the term <italic>reproducible</italic>, as used in the WORCS acronym, as being able to re-perform “the same analysis with the same code using a different analyst” (Patil et al. [<xref ref-type="bibr" rid="ref027">27</xref>]).</p>
<p>The “TOP-guidelines” are one of the most influential concrete operationalisations of general open science principles (Nosek et al. [<xref ref-type="bibr" rid="ref023">23</xref>]). These guidelines describe eight standards for open science, the first seven of which “account for reproducibility of the reported results based on the originating data, and for sharing sufficient information to conduct an independent replication” (Nosek et al. [<xref ref-type="bibr" rid="ref023">23</xref>]). These guidelines are: 1) Comprehensive citation of literature, data, materials, and methods; 2) sharing data, 3) sharing the code required to reproduce analyses, 4) sharing new research materials, and 5) sharing details of the design and analysis; 6) pre-registration of studies before data collection, and 7) pre-registration of the analysis plan prior to analysis. The eighth criterion is “not formally a transparency standard for authors”, but “addresses journal guidelines for consideration of independent replications for publication”. In this context, reproducibility can be defined as “re-performing the same analysis with the same code using a different analyst”, and replicability as “re-performing the experiment and collecting new data” (Patil et al. [<xref ref-type="bibr" rid="ref027">27</xref>]). WORCS defines the goals of open science in terms of the first seven TOP-guidelines, and the workflow and its <monospace>R</monospace> implementation are designed to facilitate compliance therewith. We group these guidelines into three categories: citation (1), sharing (2–5), and preregistration (6–7).</p>
<sec id="x1-3000-2.1">
<label>2.1.</label>
<title>Introducing the tools</title>
<p>WORCS relies solely on a set of free, open source software solutions which we will discuss before introducing the workflow.</p>
<sec id="x1-4000-2.1.1">
<label>2.1.1.</label>
<title>Dynamic document generation</title>
<p>The first is <italic>dynamic document generation</italic> (DDG): Writing scientific reports in a format that interleaves written reports with blocks of code used to conduct the analyses. The text is automatically formatted as a scientific paper in several potential styles. When the text is formatted, the code blocks are evaluated and their results are insterted in the text, or rendered as figures and tables. Dynamic document generation supersedes the classical approach of using separate programs to write prose and conduct analyses, and then manually copy-pasting analysis results into the text. This paper is an example of DDG, and its source code is <ext-link ext-link-type="uri" xlink:href="https://github.com/cjvanlissa/worcs/blob/master/paper/Manuscript_DS.Rmd">available here</ext-link>.</p>
<p>Although transitioning to DDG involves a slight learning curve, we strongly believe that the investment will pay off. Time saved from painstakingly copy-pasting output and manually formatting text soon outweighs the investment of switching to a new program. Moreover, human error in manually copying results is eliminated. When revisions require major changes to the analyses, all results, figures and tables are automatically updated. The flexibility in output formats also means that a manuscript can be rendered to presentation format, or even to a website or blog post. Moreover, the fact that code is evaluated each time the document is compiled requires researchers to work reproducibly, and allows reviewers and/or readers verify reproducibility simply by re-compiling the document. While writing academic papers in a programming environment might seem counter-intuitive at first, this approach is much more amenable to the needs of academics than most word processing software. It prevents mistakes, and saves time.</p>
<p>In the <monospace>R</monospace> implementation of WORCS, we recommend centering a research project around one dynamically generated <monospace>RMarkdown</monospace> document (Xie et al. [<xref ref-type="bibr" rid="ref047">47</xref>]). RMarkdown is based on <ext-link ext-link-type="uri" xlink:href="https://en.wikipedia.org/wiki/Markdown"><monospace>Markdown</monospace></ext-link>, which uses plain-text commands to typeset a document. It enhances this format with support for R-code, and is compatible with <ext-link ext-link-type="uri" xlink:href="https://www.latex-project.org/">LaTeX</ext-link> math typesetting. For a full overview of the functionality of <monospace>RMarkdown</monospace>, see Xie et al. [<xref ref-type="bibr" rid="ref047">47</xref>].</p>
<p>The RMarkdown document can incorporate blocks of analysis code, which can be used to render results directly to <ext-link ext-link-type="uri" xlink:href="https://bookdown.org/yihui/rmarkdown-cookbook/kable.html">Tables</ext-link> and <ext-link ext-link-type="uri" xlink:href="http://zevross.com/blog/2017/06/19/tips-and-tricks-for-working-with-images-and-figures-in-r-markdown-documents/">Figures</ext-link>, which can be <ext-link ext-link-type="uri" xlink:href="https://bookdown.org/yihui/rmarkdown-cookbook/cross-ref.html">dynamically referenced</ext-link> in the text. Long scripts can be stored in <monospace>.R</monospace> files, and included in the main document using the <ext-link ext-link-type="uri" xlink:href="https://github.com/yihui/knitr-examples/blob/master/113-externalization.Rmd"><monospace>read_chunk()</monospace> function</ext-link> from the <monospace>knitr</monospace> package, which comes together with the <monospace>rmarkdown</monospace> package. When a reader or reviewer compiles this document, all code is run automatically, thus verifying computational replicability. The <monospace>RMarkdown</monospace> document can be automatically formatted in many styles, including APA style (thanks to the <monospace>R</monospace> package <monospace>papaja</monospace>, Aust and Barth [<xref ref-type="bibr" rid="ref007">7</xref>]), a host of other scientific formats (see Allaire et al. [<xref ref-type="bibr" rid="ref004">4</xref>]), and as plain <monospace>Markdown</monospace>.</p>
</sec>
<sec id="x1-5000-2.1.2">
<label>2.1.2.</label>
<title>Version control</title>
<p>The second solution is <italic>version control</italic>: Maintaining an indelible log of every change to all project files. Version control is a near-essential tool for scientific reproducibility, as anyone learns who has had the experience of accidentally deleting a crucial file, or of being unable to reproduce analyses because they ran some analyses interactively, instead of documenting the syntax in a script file (see also Blischak et al. [<xref ref-type="bibr" rid="ref009">9</xref>]). Many scientists use some form of <italic>implicit</italic> version control; for example, by renaming files after major changes (e.g., “manuscript_final_2.2-2019-10-12.doc”), tracking changes in word processing software, or using cloud hosting services that retain backups of previous versions.</p>
<p>An integral part of WORCS is the <italic>explicit</italic> version control software Git (<ext-link ext-link-type="uri" xlink:href="http://www.git-scm.com">www.git-scm.com</ext-link>). A project version controlled with Git is called a “repository”, or repo. Git tracks changes to files in the repository on a line-by-line basis. The user can store these changes by making a “commit”: a snapshot of the version controlled files. Each “commit” can contain as many changes as desired; for example, a whole new paragraph, or many small changes made to address a single reviewer comment. Each commit is further tagged with a message, describing the changes. The <monospace>R</monospace> implementation of <monospace>worcs</monospace> contains a convenience function, <monospace>git_update("your commit message")</monospace>, which creates a new commit for all changes since the previous commit, labels it with “your commit message”, and pushes these changes to the remote repository. It is, effectively, a Git “quick save” command.</p>
<p>From an open science perspective, Git is particularly appealing because it retains a complete historical backlog of all commits. This can be used, for example, to verify that authors executed the steps outlined in a preregistration. Users can also compare changes between different commits, or go back to a previous version of the code (for example, after making a mistake, or to replicate a previous version of the results). Git only version controls files explicitly committed by the user. Moreover, it is possible to prevent files from being version controlled – which is useful for privacy sensitive data. A <monospace>.gitignore</monospace> file lists files that should not be version-controlled. These files thus exist only on the user’s computer.</p>
<p>The functionality of Git is enhanced by services such as GitHub (<uri>https://github.com</uri>). GitHub is best understood as a cloud storage service with social networking functionality. The cloud storage aspect of GitHub allows you to “clone” (copy) a local Git repository to the GitHub website, as a backup or research archive. The GitHub platform offers additional functionality over Git. One such feature is that specific stages in the lifecycle of a project can be <ext-link ext-link-type="uri" xlink:href="https://docs.github.com/en/free-pro-team@latest/github/administering-a-repository/managing-releases-in-a-repository">tagged as a “release”</ext-link>: A named downloadable snapshot of a specific state of the project, that is prominently featured on the GitHub project page. The WORCS procedure encourages users to create releases to demarcate project milestones such as preregistration and submission to a journal. Releases are also useful to mark the submission of a revised manuscript, and publication.</p>
<p>The social network aspect of GitHub comes into play when a repository is made “public”: This allows other researchers to peruse the repository and see how the work was done; clone it to their own computer to replicate the original work or apply the methods to their own data; open “Issues” to ask questions or give feedback on the project, or even send a “Pull request” with suggested changes to the text or code for your consideration. Git and GitHub shine as tools for collaboration, because different people can simultaneously work on different parts of a project, and their changes can be compared and automatically merged on the website. Even on solo projects, working with Git/GitHub has many benefits: Staying organized, being able to start a new study with a clone of an old, similar repository, or splitting off an “experimental branch” to try something new, while retaining the ability to “revert” (return) to a previous state of the project, or to “merge” (incorporate) the experimental branch.</p>
<p>Although GitHub is the most widely used remote repository, <monospace>worcs</monospace> <ext-link ext-link-type="uri" xlink:href="https://cjvanlissa.github.io/worcs/articles/git_cloud.html">supports alternative services</ext-link>. We will refer to all such services as “remote repositories”. The <monospace>worcs</monospace> package uses <monospace>gert</monospace> (Ooms [<xref ref-type="bibr" rid="ref026">26</xref>]) to connect a local project to a remote repository. It also includes user-friendly functions to set user credentials, <monospace>git_user()</monospace>, and to add, commit, and push changed files to a remote repository in one step, <monospace>git_update()</monospace>.</p>
</sec>
<sec id="x1-6000-2.1.3">
<label>2.1.3.</label>
<title>Dependency management</title>
<p>The third solution is <italic>dependency management</italic>: Keeping track of exactly what software was used to conduct the analyses. At first glance, it might seem sufficient to state that analyses were conducted in <italic>Program X</italic>. However, every program is susceptible to changes, updates, and bugfixes. Open Source software, in particular, is regularly updated because there is an active community of developers contributing functionality and bugfixes. Potentially, any such update could change the results of the code, thus rendering the analysis computationally non-reproducible.</p>
<p>Many solutions exist to ensure computational reproducibility, which differ in user-friendliness and effectiveness. These solutions typically work by enveloping your research project in a distinct “environment” that only has access to programs that are explicitly installed, and maintaining a record of these programs. When choosing an appropriate solution for dependency management, there is a tradeoff between ease-of-use on the one hand, and robustness on the other. In making this tradeoff, it is important to consider that all solutions have a limited shelf life (Brown [<xref ref-type="bibr" rid="ref010">10</xref>]). Therefore, the best approach might be to use a “good-enough” solution, and acknowledge that all code requires some maintenance if you want to reproduce it in the future.</p>
<p>For dependency management, the <monospace>R</monospace> implementation of <monospace>worcs</monospace> relies on the recently released package <monospace>renv</monospace> (Ushey [<xref ref-type="bibr" rid="ref040">40</xref>]). This package strikes a great balance between user-friendliness and robustness. Developed by the team behind RStudio, <monospace>renv</monospace> maintains a text-based, human-readable log of all packages used, their version numbers, and where they were installed from (e.g., CRAN, Bioconductor, GitHub). This text-based log file can be version controlled with Git. When someone else loads your project, <monospace>renv</monospace> will install all of the required packages from this list. This lightweight approach safeguards reproducibility as long as these repositories maintain their archives. The <monospace>worcs</monospace> project template in RStudio automatically sets up <monospace>renv</monospace> for dependency management if the checkbox labeled “renv” is selected during project creation.</p>
<p>All solutions to computational reproducibility require users to make their dependencies explicit, often by reinstalling all software for each project in a controlled environment. This can lead to long installation times and large memory requirements. Similarly, <monospace>renv</monospace> requires users to call <monospace>install.packages()</monospace> for each library used – but it does not reinstall packages for each new project. Instead, packages reside in a cache that is shared between all projects on the computer. If a project uses a package that is already in the cache, it is not reinstalled, but linked from the cache. This improves the user experience by saving time and memory. As opposed to alternative solutions, <monospace>renv</monospace> is tightly integrated with the native R package management system. It monitors the scripts in the project directory for <monospace>library()</monospace> calls, and notifies the user when it is necessary to update the dependencies file using the <monospace>snapshot()</monospace> function. Therefore, <monospace>renv</monospace> does not require the users to change their workflow of installing/removing and using packages, and requires little technical skill to setup. It is not a fail-safe method to ensure strict computational reproducibility, but it meets most reproducibility requirements using only tools native to <monospace>R</monospace> and RStudio.</p>
<p>When a project is conducted in a different software environment than <monospace>R</monospace>, or if an R-project has external dependencies not tracked by <monospace>renv</monospace>, then users might choose to use <ext-link ext-link-type="uri" xlink:href="https://www.docker.com/">Docker</ext-link> for dependency management.</p>
<p>Docker instantiates a “Docker container”: An environment that behaves like a virtual computer, which can be stored like a time capsule, and identically reinstated on a user computer, or in the cloud. Although the use of Docker falls outside of the scope of the present paper, for existing users, a Docker build running <monospace>worcs</monospace> and its dependencies is available. The <ext-link ext-link-type="uri" xlink:href="https://cjvanlissa.github.io/worcs/articles/setup-docker.html">stetup with Docker vignette</ext-link> explains how to instantiate this build. For more information on this topic, Peikert and Brandmaier [<xref ref-type="bibr" rid="ref028">28</xref>] describe a Docker-based workflow for computational reproducibility that is conceptually and practically compatible with WORCS.</p>
<p>As Docker is somewhat challenging to set up for novice users, an <monospace>R</monospace> package is currently in development to facilitate Docker integration (<monospace>repro</monospace>, Peikert et al. [<xref ref-type="bibr" rid="ref029">29</xref>]). Another example of a Docker-based workflow is the cloud-based collaboration platform “Code Ocean”. This platform greatly simplifies setting up a reproducible computing environment with version control and dependency management. A key feature is that collaborators can log in to the server session, rather than each having to set up Docker on a local computer. One important consideration when using any cloud-computing solution is the necessity to upload human participant data for analysis. Such a platform would need to comply with relevant laws and ethical requirements. For example, as of this writing, the <ext-link ext-link-type="uri" xlink:href="https://codeocean.com/terms-of-use">terms of use</ext-link> for Code Ocean do not address the GDPR, nor is it clear where data are stored. This is a potential liability for European scholars.</p>
</sec>
</sec>
<sec id="x1-7000-2.2">
<label>2.2.</label>
<title>Text-based files are better</title>
<p>A key consideration when developing a research project is what filetypes to use. WORCS encourages the use of text-based files whenever possible, instead of binary files. Text-based files can be read by machines and humans alike. Binary files, such as Word (<monospace>.docx</monospace>) or SPSS (<monospace>.sav</monospace>, <monospace>.spo</monospace>) files, must be decoded first, often requiring commercial software. Although binary files can be version controlled with Git, their change log is uninterpretable. Binary files are also often larger than text-based files, which means they take up more space on cloud hosting services. For these reasons, uploading large binary files to remote repositories is frowned upon.</p>
<p>Two additional points are worth noting: First, as Git tracks line-by-line changes, it is recommended to start each sentence on a new line. That way, the change log will indicate which specific sentence was edited, instead of replacing an entire paragraph. As RMarkdown does not parse a single line break as the end of a paragraph, this practice does not disrupt the flow of a paragraph in the rendered version. Second, the remote repository GitHub renders certain text-based filetypes for online viewing: For example, <monospace>.md</monospace> (Markdown) files are displayed as web pages, and <monospace>.csv</monospace> files as spreadsheets. The <monospace>worcs</monospace> package uses this feature to, for example, render a codebook for the data as <monospace>.md</monospace> so it will be shown as a web page on GitHub.</p>
</sec>
</sec>
<sec id="x1-8000-3">
<label>3.</label>
<title>Introducing the workflow</title>
<p>We provide a conceptual outline of the WORCS procedure below, based on WORCS Version 0.1.6. The conceptual workflow recommends actions to take in the different phases of a research project, in order to work openly and transparently in compliance with the TOP-guidelines and best practices for open science. Note that, although the steps are numbered for reference purposes, we acknowledge that the process of conducting research is not always linear. We refer users of the <monospace>worcs</monospace> implementation in <monospace>R</monospace> to <ext-link ext-link-type="uri" xlink:href="https://cjvanlissa.github.io/worcs/articles/setup.html">the workflow vignette</ext-link>, which describes in more detail which steps are automated by the <monospace>R</monospace> package and which actions must be taken by the user. The vignette is also updated with future developments of the package. For examples of how the workflow is used in practice, we maintain <ext-link ext-link-type="uri" xlink:href="https://github.com/cjvanlissa/worcs/tree/master#adoption-of-worcs-by-users">a list of public <monospace>worcs</monospace> projects</ext-link> on the WORCS GitHub page.</p>
<sec id="x1-9000-3.1">
<label>3.1.</label>
<title>Phase 1: Study design</title>
<p>
<list>
<list-item id="x1-9001x-3.1">
<label>1.</label>
<p>Create a (Public or Private) remote repository on a “Git” hosting service</p>
</list-item>
<list-item id="x1-9002x-3.1">
<label>2.</label>
<p>When using R, initialize a new RStudio project using the WORCS template. Otherwise, clone the remote repository to your local project folder.</p>
</list-item>
<list-item id="x1-9003x-3.1">
<label>3.</label>
<p>Add a README.md file, explaining how users should interact with the project, and a LICENSE to explain users’ rights and limit your liability. This is automated by the <monospace>worcs</monospace> package.</p>
</list-item>
<list-item id="x1-9004x-3.1">
<label>4.</label>
<p>Optional: Preregister your analysis by committing a plain-text preregistration and <ext-link ext-link-type="uri" xlink:href="https://docs.github.com/en/free-pro-team@latest/github/administering-a-repository/managing-releases-in-a-repository">tag this commit</ext-link> with the label “preregistration”.</p>
</list-item>
<list-item id="x1-9005x-3.1">
<label>5.</label>
<p>Optional: Upload the preregistration to a dedicated preregistration server</p>
</list-item>
<list-item id="x1-9006x-3.1">
<label>6.</label>
<p>Optional: Add study materials to the repository</p>
</list-item>
</list>
</p>
</sec>
<sec id="x1-10000-3.2">
<label>3.2.</label>
<title>Phase 2: Writing and analysis</title>
<p>
<list>
<list-item id="x1-10001x-3.2">
<label>7.</label>
<p>Create an executable script documenting the code required to load the raw data into a tabular format, and de-identify human subjects if applicable</p>
</list-item>
<list-item id="x1-10002x-3.2">
<label>8.</label>
<p>Save the data into a plain-text tabular format like <monospace>.csv</monospace>. When using open data, commit this file to “Git”. When using closed data, commit a checksum of the file, and a synthetic copy of the data.</p>
</list-item>
<list-item id="x1-10003x-3.2">
<label>9.</label>
<p>Write the manuscript using a dynamic document generation format, with code chunks to perform the analyses.</p>
</list-item>
<list-item id="x1-10004x-3.2">
<label>10.</label>
<p>Commit every small change to the “Git” repository</p>
</list-item>
<list-item id="x1-10005x-3.2">
<label>11.</label>
<p>Use comprehensive citation</p>
</list-item>
</list>
</p>
</sec>
<sec id="x1-11000-3.3">
<label>3.3.</label>
<title>Phase 3: Submission and publication</title>
<p>
<list>
<list-item id="x1-11001x-3.3">
<label>12.</label>
<p>Use dependency management to make the computational environment fully reproducible</p>
</list-item>
<list-item id="x1-11002x-3.3">
<label>13.</label>
<p>Optional: Add a WORCS-badge to your project’s README file</p>
</list-item>
<list-item id="x1-11003x-3.3">
<label>14.</label>
<p>Make a Private “Git” remote repository Public</p>
</list-item>
<list-item id="x1-11004x-3.3">
<label>15.</label>
<p><ext-link ext-link-type="uri" xlink:href="https://help.osf.io/hc/en-us/articles/360019737594-Create-a-Project">Create a project page on the Open Science Framework (OSF)</ext-link> and <ext-link ext-link-type="uri" xlink:href="https://help.osf.io/hc/en-us/articles/360019929813-Connect-GitHub-to-a-Project">connect it to the “Git” remote</ext-link> <ext-link ext-link-type="uri" xlink:href="https://help.osf.io/hc/en-us/articles/360019929813-Connect-GitHub-to-a-Project">repository</ext-link></p>
</list-item>
<list-item id="x1-11005x-3.3">
<label>16.</label>
<p><ext-link ext-link-type="uri" xlink:href="https://help.osf.io/hc/en-us/articles/360019931013-Create-DOIs">Generate a Digital Object Identifier (DOI) for the OSF project</ext-link></p>
</list-item>
<list-item id="x1-11006x-3.3">
<label>17.</label>
<p>Add an open science statement to the Abstract or Author notes, which links to the “OSF” project page and/or the “Git” remote repository</p>
</list-item>
<list-item id="x1-11007x-3.3">
<label>18.</label>
<p>Render the dynamic document to PDF</p>
</list-item>
<list-item id="x1-11008x-3.3">
<label>19.</label>
<p>Optional: <ext-link ext-link-type="uri" xlink:href="https://help.osf.io/hc/en-us/articles/360019930533-Upload-a-Preprint">Publish the PDF as a preprint, and add it to the OSF project</ext-link></p>
</list-item>
<list-item id="x1-11009x-3.3">
<label>20.</label>
<p>Submit the paper, and <ext-link ext-link-type="uri" xlink:href="https://docs.github.com/en/free-pro-team@latest/github/administering-a-repository/managing-releases-in-a-repository">tag the commit of the submitted paper as a release</ext-link> of the submitted paper as a release, as in Step 4.</p>
</list-item>
</list>
</p>
</sec>
<sec id="x1-12000-3.4">
<label>3.4.</label>
<title>Notes for cautious researchers</title>
<p>Some researchers might want to share their work only once the paper is accepted for publication. In this case, we recommend creating a “Private” repository in Step 1, and completing Steps 13-18 upon acceptance.</p>
</sec>
<sec id="x1-13000-3.5">
<label>3.5.</label>
<title>The R implementation of WORCS</title>
<p>WORCS is, first and foremost, a conceptual workflow that could be implemented in any software environment. As of this writing, the workflow has been implemented for <monospace>R</monospace> users in the package <monospace>worcs</monospace> (Van Lissa et al. [<xref ref-type="bibr" rid="ref041">41</xref>]). Several arguments support our choice to implement this workflow first in <monospace>R</monospace> and RStudio, although we encourage developers to port the software to other languages. First, <monospace>R</monospace> and all of it extensions are free open source software, which make it a tool of choice for open science. Second, all tools required for an open science workflow are implemented in <monospace>R</monospace>, most of these tools are directly accessible through the RStudio user interface, and some of them are actively developed by the team behind RStudio. Third, RStudio is a Public Benefit Corporation, whose commitment to open science is codified in the company charter: <disp-quote>
<p>RStudio’s primary purpose is to create free and open-source software for data science, scientific research, and technical communication. This allows anyone with access to a computer to participate freely in a global economy that rewards data literacy; enhances the production and consumption of knowledge; and facilitates collaboration and reproducible research in science, education and industry.</p></disp-quote></p>
<p>Fourth, <monospace>R</monospace> is the second-most cited statistical software package (Muenchen [<xref ref-type="bibr" rid="ref022">22</xref>]), following SPSS, which has no support for any of the open science tools discussed in this paper. Fifth, <monospace>R</monospace> is well-supported by a vibrant and inclusive online community, which develops new methods and packages, and provides support and tutorials for existing ones. Finally, <monospace>R</monospace> is highly interoperable: Packages are available to read and write nearly every filetype, including DOCX, PDF (in APA style), and HTML. Moreover, wrappers are available for many tools developed in other programming languages, and code written in other programming languages can be evaluated from <monospace>R</monospace>, including <monospace>C++</monospace>, <monospace>Fortran</monospace>, and <monospace>Python</monospace> (Allaire et al. [<xref ref-type="bibr" rid="ref005">5</xref>]). There are excellent free resources for learning <monospace>R</monospace> (e.g., Grolemund and Wickham [<xref ref-type="bibr" rid="ref014">14</xref>]).</p>
<p>Working with <monospace>R</monospace> is simplified immensely by using the RStudio integrated development engine (IDE) for <monospace>R</monospace> (RStudio Team [<xref ref-type="bibr" rid="ref035">35</xref>]). RStudio automates and streamlines tedious or complicated aspects of working with the tools used in WORCS, and many are embedded directly into the visual user interface. This makes RStudio a comprehensive solution for open science research projects. Another important feature of RStudio is project management. A project bundles writing, analyses, data, references, et cetera, into a self-contained folder, that can be uploaded entirely to a Git remote repository and downloaded by future users. The <monospace>worcs R</monospace> package installs a new RStudio project template. When a new project is initialized from this template, the bookkeeping required to set up an open science project is performed automatically.</p>
<sec id="x1-14000-3.5.1">
<label>3.5.1.</label>
<title>Preparing your system</title>
<p>Before you can use the <monospace>R</monospace> implementation of the WORCS workflow, you have to install the required software. This 30 minute procedure is documented in <ext-link ext-link-type="uri" xlink:href="https://cjvanlissa.github.io/worcs/articles/setup.html">the setup vignette</ext-link>. After setting up your system, you can use <monospace>worcs</monospace> for all of your projects. Alternatively, Docker users can follow <ext-link ext-link-type="uri" xlink:href="https://cjvanlissa.github.io/worcs/articles/setup-docker.html">the stetup with Docker vignette</ext-link>. The <monospace>R</monospace> implementation of the workflow introduced earlier is detailed, step-by-step, in <ext-link ext-link-type="uri" xlink:href="https://cjvanlissa.github.io/worcs/articles/workflow.html">the workflow vignette</ext-link>.</p>
</sec>
</sec>
</sec>
<sec id="x1-15000-4">
<label>4.</label>
<title>How WORCS helps meet the TOP-guidelines</title>
<sec id="x1-16000-4.1">
<label>4.1.</label>
<title>Comprehensive citation</title>
<p>The TOP-guidelines encourage comprehensive citation of literature, data, materials, methods, and software. In principle, researchers can meet this requirement by simply citing every reference used. Unfortunately, citation of data and software is less commonplace than citation of literature and materials. Crediting these resources is important, because it incentivizes data sharing and the development of open-source software, supports the open science efforts of others, and helps researchers receive credit for <italic>all</italic> of their research output, in line with the San Francisco Declaration on Research Assessment, <ext-link ext-link-type="uri" xlink:href="https://sfdora.org/">DORA</ext-link>.</p>
<p>To facilitate citing datasets, researchers sometimes publish <italic>data papers</italic>; documents that detail the procedure, sample, and codebook. Specialized journals, such as the <ext-link ext-link-type="uri" xlink:href="https://openpsychologydata.metajnl.com/"><italic>Journal of Open Psychology Data</italic></ext-link>, aid in the publication of these data papers. For smaller projects, researchers often simply share the data in a remote repository, along with a text file with the preferred citation for the data (which can be a substantive paper), and the license that applies to the data, such as Creative Commons <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-sa/4.0/">BY-SA</ext-link> or <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc-sa/4.0/">BY-NC-SA</ext-link>. When in doubt, one can always contact the data creators and ask what the preferred citation is.</p>
<p>References for software are sometimes provided within the software environment; for example, in <monospace>R</monospace>, package references can be found by calling <monospace>citation("packagename")</monospace>. This returns an APA-style reference, and a BibTeX entry. Software papers are also common, and are sometimes called “Application Notes”. The <ext-link ext-link-type="uri" xlink:href="https://joss.theoj.org/">Journal of Open Source Software (JOSS)</ext-link> offers programmers a way to generate a publication based on well-documented software; in this process, the code itself is peer reviewed, and writing an actual paper is optional. For an example, see Rosenberg et al. [<xref ref-type="bibr" rid="ref034">34</xref>]. Software citations can also sometimes be found in the source code repository (e.g., on Git remote repositories), using the <ext-link ext-link-type="uri" xlink:href="https://citation-file-format.github.io/">“Citation File Format”</ext-link>. The <ext-link ext-link-type="uri" xlink:href="https://www.softwareheritage.org/2020/05/26/citing-software-with-style/"><italic>Software Heritage Project</italic></ext-link> recently published a BibLaTeX software citation style that will further facilitate accurate citation of software in dynamically generated documents.</p>
<p>One important impediment to comprehensive citation is the fact that print journals operate with space constraints. Print journals often discourage comprehensive citation, either actively, or passively by including the reference list in the manuscript word count. Researchers can overcome this impediment by preparing two versions of the manuscript: One version with comprehensive citations for online dissemination, and another version for print, with only the essential citations. The print version should reference the online version, so interested readers can find the comprehensive reference list. The WORCS procedure suggests uploading the online version to a preprint server. This is important because most major preprint servers – including <ext-link ext-link-type="uri" xlink:href="https://arxiv.org">arXiv.org</ext-link> and all preprint services hosted by the <ext-link ext-link-type="uri" xlink:href="https://help.osf.io/hc/en-us/articles/360019930493-Preprint-FAQs#how_do_i_find_preprints">Open Science Framework (OSF)</ext-link> – are indexed by Google Scholar. This means that authors will receive credit for cited work; even if they are cited only in the online version. Moreover, preprint servers ensure that the online version will have a persistent DOI, and will remain reliably accessible, just like the print version.</p>
</sec>
<sec id="x1-17000-4.2">
<label>4.2.</label>
<title>Implementation in worcs</title>
<p>The <monospace>worcs</monospace> package includes a <ext-link ext-link-type="uri" xlink:href="https://cjvanlissa.github.io/worcs/articles/citation.html">vignette on citation</ext-link> to explain the fundamentals for novice users, and offer recommendations specific to <monospace>worcs</monospace>. We recommend using the free, open-source reference manager <ext-link ext-link-type="uri" xlink:href="https://www.zotero.org/download/">Zotero</ext-link>; it is feature-rich, user-friendly, and highly interoperable with other reference managers. A tutorial for using Zotero with RMarkdown exists <ext-link ext-link-type="uri" xlink:href="https://christopherjunk.netlify.com/blog/2019/02/25/zotero-RMarkdown/">here</ext-link>.</p>
<p>The <monospace>worcs</monospace> package also offers original solutions for comprehensive citation. Firstly, during the writing process, authors can mark the distinction between essential and non-essential references. It is easier to do this from the start, instead of going back to cut non-essential references just prior to publication. Standard Markdown uses the at-symbol (<monospace>@</monospace>) to cite a reference. <monospace>worcs</monospace> additionally reserves the “double at”-symbol (<monospace>@</monospace>) to cite a non-essential reference. Users can render the manuscript either with, or without, comprehensive citations by adapting the <monospace>knit</monospace> command in the front matter, setting it to <monospace>knit: worcs::cite_all</monospace> to render all citations, and to <monospace>knit: worcs::cite_essential</monospace> to remove all <italic>non-essential</italic> citations.</p>
<p>With regard to the citation of <monospace>R</monospace> packages, it is worth noting that the <monospace>papaja</monospace> package (Aust and Barth [<xref ref-type="bibr" rid="ref007">7</xref>]), which provides the <monospace>APA6</monospace> template used in <monospace>worcs</monospace>, also includes functions to automatically cite all packages used in the <monospace>R</monospace> session, and add their references to the bibliography file.</p>
</sec>
<sec id="x1-18000-4.3">
<label>4.3.</label>
<title>Data sharing</title>
<p>Data sharing is important for computational reproducibility and secondary analysis. Computational reproducibility means that a third party can exactly recreate the results from the original data, using the published analysis code. Secondary analysis means that a third party can conduct sensitivity analyses, explore alternative explanations, or even use existing data to answer a different research question. If it is possible to share the data, these can simply be pushed to a Git remote repository, along with documentation (such as a codebook) and the analysis code. This way, others can download the entire repository and reproduce the analyses from start to finish. From an open science perspective, data sharing is always desirable. From a practical point of view, it is not always possible.</p>
<p>Data sharing may be impeded by several concerns. One technical concern is whether data require special storage provisions, as is often the case with “big data”. Most Git remote repositories do not support files larger than 100 MB, but it is possible to enhance a Git repository with <ext-link ext-link-type="uri" xlink:href="https://git-lfs.github.com/">Git Large File Storage</ext-link> to add remotely stored files as large as several GB. Files exceeding this size require custom solutions beyond the scope of this paper.</p>
<p>Sharing human participant data additionally entails legal and ethical concerns. Before sharing any human participant data, it is recommended to obtain approval from qualified ethical and legal advisory organs, guidance from Research Data Management Support, and informed consent from participants. Many legislatures require researchers to “de-identify” human subject data upon collection, by removing or deleting any sensitive personal information and contact details. However, when researchers have an imperfect understanding of the legal obligations and dispensations, they can end up over- or undersharing, and risk either placing participants at risk of being identified, or undermine the replicability of their own work and potential reuse value of their data (Phillips and Knoppers [<xref ref-type="bibr" rid="ref030">30</xref>]). Furthermore, it is important to note that the European GDPR prohibits storing “personal data” (information which can identify a natural person whether directly or indirectly) on a server outside the EU, unless it offers an “adequate level of protection”. Although different rules may apply to pseudonimized data, there are many repositories that are GDPR compliant, such as the European servers of the Open Science Framework. Different Universities, countries, and funding bodies also have their own repositories that are complient with local legistation. In sum, data should only be shared after consult qualified legal and ethical advisory organs, obtaining informed consent from participants, and de-identifying or pseudononimizing data.</p>
<p>If data cannot be shared, researchers should aim to safeguard the potential for computational reproducibility and secondary analysis as much as possible. WORCS recommends two solutions to accomplish this goal. The first solution is to publish a <italic>checksum</italic> of the original data file (Rivest [<xref ref-type="bibr" rid="ref033">33</xref>]). Think of a checksum as a 32-character unique identifier,<xref ref-type="fn" rid="fn-1">1</xref><fn id="fn-1"><label><sup>1</sup></label>
<p>It is theoretically possible but improbable that random changes to a file will result in the same checksum.</p></fn> or as a lossy “summary” of the contents of a file. Any change to the file will result in a different checksum. Thus, one can use a checksum to verify the identity of a file, and ensure that its contents are unchanged. When data cannot be shared, the risk of fraud or abuse can be mitigated by publishing a checksum for the original data, in addition to the complete analysis code. Using the checksum to verify the identity of a private dataset, researchers can prove to an independent auditor that running the public analysis code on the private data results in the published results of their work.</p>
<p>A second solution is to share a synthetic dataset with similar characteristics to the real data. Synthetic data mimic the level of measurement and (conditional) distributions of the real data (see Nowok et al. [<xref ref-type="bibr" rid="ref025">25</xref>]). Sharing synthetic data allows any third party to 1) verify that the published code works, 2) debug the code, and 3) write valid code for alternative analyses. It is important to note that complex multivariate relationships present in the real data are often lost in synthetic data. Thus, findings from the real data might not be replicated in the synthetic data, and findings in the synthetic data <italic>should not be substantively interpreted</italic>. Still, sharing synthetic data facilitates data requests from third parties. A third party can write analysis code based on the synthetic data, and send it to the authors who evaluate it on the real data and send back the results. The <monospace>worcs</monospace> package offers a simple but flexible function to generate synthetic data, <monospace>synthetic()</monospace>. This function is based on the work by Nowok et al. [<xref ref-type="bibr" rid="ref025">25</xref>] (see the <monospace>R</monospace> package <monospace>synthpop</monospace>), but with a simpler and more flexible user interface. Specifically, the <monospace>worcs</monospace> function <monospace>synthetic()</monospace> accepts any function that can be used to model marginal associations in the data. By default, this function uses random forests, as implemented in the <monospace>ranger</monospace> package, to generate a model for synthesis (Wright and Ziegler [<xref ref-type="bibr" rid="ref046">46</xref>]). Note that the <monospace>ranger()</monospace> function does not handle all available data types in <monospace>R</monospace>. Users can call custom functions to build a prediction model for unsupported data types, using the argument <monospace>model_expression</monospace>. For further details, see the <ext-link ext-link-type="uri" xlink:href="https://cjvanlissa.github.io/worcs/reference/synthetic.html">function documentation</ext-link>.</p>
<p>Note that for data synthesis to work properly, it is essential that the <monospace>class</monospace> (data type) of variables is defined correctly. As of <monospace>worcs</monospace> version 0.1.6, numeric, integer, factor, and logical data are supported out of the box. Other types of variables should be converted to one of these types. It is important to consider this when using special data types, such as the labeled vectors created by the <monospace>haven</monospace> package when reading an SPSS file. We further caution that the default random forests algorithm is computationally intensive, and may be unfeasible for use with “large” datasets. Users can provide use a custom <monospace>model_expression</monospace> and <monospace>predict_expression</monospace> to use a different algorithm when calling <monospace>synthetic()</monospace>. For example, users could use <monospace>lm()</monospace> as a <monospace>model_expression</monospace> to use linear regression, which preserves linear marginal relationships but can give rise to values out of range of the original data. Or users could call <monospace>sample()</monospace> as a <monospace>predict_expression</monospace> to bootstrap each variable, a very quick solution that maintains univariate distributions but loses all marginal relationships.</p>
<sec id="x1-19000-4.3.1">
<label>4.3.1.</label>
<title>Processing data in WORCS</title>
<p>When initializing a new <monospace>worcs</monospace> project, an empty <monospace>R</monospace> script called <monospace>prepare_data.R</monospace> is generated. As soon as raw data are collected, researchers should use this file to document all steps necessary to load the data into <monospace>R</monospace>, pseudonimize it, and prepare it for analysis. As data should be shared in a format as close to raw as possible, this script should be as short as possible and only document the minimum necessary steps. For example, if the data was originally in SPSS format with IP addresses and GPS location, this file might just contain the code required to read the SPSS file, and to remove those columns of sensitive personal information. As soon as the data are pseudonimized and processed into tabular (spreadsheet-like) format, the researcher should version control some indelible record of the raw data. The concept of “tidy” data is a helpful standard; i.e., clean, tabular data that is formatted in a way that facilitates further analysis (see Wickham [<xref ref-type="bibr" rid="ref044">44</xref>]).</p>
<p>One issue of concern is the practice of “fixing” mistakes in the data. It is not uncommon for researchers to perform such corrections manually in the raw data, even if all other analysis steps are documented. Regardless of whether the data will be open or closed, it is important that the raw data be left unchanged as much as possible. This eliminates human error. Any alterations to the data – including processing steps and even error corrections – should be documented in the code, instead of applied to the raw data. This way, the code will be a pipeline from the raw data to the published results. Thus, for instance, if data have been entered manually in a spreadsheet, and a researcher discovers that in one of the variables, missing values were coded as <monospace>-99</monospace> whereas they were coded as <monospace>-9</monospace> in all other variables, then we would recommend adding a line of code to recode the missing values – thereby documenting the mistake – instead of “fixing” it by editing the raw spreadsheet.</p>
<p>The <monospace>worcs</monospace> package offers two functions for version controlling a record of the data: One for open, and one for closed data. Researchers should assume that the decision to make data open is irreversible. Thus, the decision should be made well before arriving at this stage in the workflow. If there is any doubt, it is prudent to proceed with closed data and make the data open once all doubt is assuaged.</p>
<p>In <monospace>worcs</monospace>, researchers can call the function <monospace>open_data(data)</monospace> to make the data publicly available. This function stores the <monospace>data</monospace> object (such as a <monospace>data.frame</monospace> or <monospace>matrix</monospace>) in a tabular data file. It also generates an accompanying codebook – a human-readable document that serves as a legend for the tabular data file – that can be viewed online. All changed files should now be added to the Git repository, committed, and pushed to the remote repository. This can be done through the Git panel in RStudio, or by running the <monospace>worcs</monospace> function <monospace>git_update("commit message")</monospace>. Once the remote repository is made public, these data will be open to the public. Assume that, once this is done, the data cannot be un-shared.</p>
<p>Alternatively, if the project requires data to remain closed, researchers can call <monospace>closed_data(data)</monospace>. This function also stores the data in a local <monospace>.csv</monospace> file and generates a codebook, but the original data file is added to <monospace>.gitignore</monospace> so it cannot be accidentally added to the Git repository. The function also computes a checksum for the original data, and logs it in the <monospace>.worcs</monospace> project file. This checksum serves as the indelible record of the state of the raw data. The function <monospace>closed_data()</monospace> also calls the aforementioned <monospace>synthetic()</monospace> function to create a synthetic dataset. The user should push all changed files to the remote repository. Once the remote repository is made public, people will have access to a checksum for the original data that exist on your local machine, a codebook describing those data, and a synthetic copy of the data. Keep in mind that, when using closed data, the original data file exists only on the user’s computer. Adequate provisions to back up the data, while respecting principles of responsible data stewardship, should be made.</p>
<p>As the purpose of the <monospace>prepare_data.R</monospace> file is to prepare data for sharing, the final line of this file should typically be either <monospace>open_data()</monospace> or <monospace>closed_data()</monospace>.</p>
<p>After generating tidy, shareable data, this data is then loaded in the analysis code with the function <monospace>load_data()</monospace>. This function only loads the real data if it is available on the user’s computer, and otherwise, loads the synthetic data. This will have the effect that third party users who copy a remote repository with closed data will automatically load the synthetic dataset, whereas the study authors, who have the real data stored locally, will automatically load the real data. This makes it possible for reviewers, coauthors, and auditors, to write analysis scripts without requiring access to the original data. They can simply start the script with <monospace>load_data()</monospace>, and write their code based on the synthetic data. Then, they can submit their code to you – by email or as a <ext-link ext-link-type="uri" xlink:href="https://help.github.com/en/github/collaborating-with-issues-and-pull-requests/creating-a-pull-request">“Pull request”</ext-link>. When you run their code on your system, <monospace>load_data()</monospace> will load the original data, and use that to run their script. You can then return the results to the third party.</p>
<p>Note that these functions can be used to store multiple data files, if necessary. As of version 0.1.2, the <monospace>worcs</monospace> package only stores data as <monospace>.csv</monospace> files. As explained above, this is recommended, because <monospace>.csv</monospace> files are human- and machine readable, and because data typically need to be in tabular format for analysis. Many types of data can be represented as a table; for example, text corpora can have one row per document, and EEG- or ECG waveforms can have a row per measurement occasion and a column per channel. The <monospace>prepare_data.R</monospace> file should document any steps required to convert these data into tabular format. If this is not an appropriate format for the data, readers are encouraged to follow the development of the <monospace>repro</monospace> package (Peikert et al. [<xref ref-type="bibr" rid="ref029">29</xref>]), which will offer greater support for reproducibly storing and retrieving diverse data formats.</p>
<p>Some users may intend to make their data openly available through a restricted access platform, such as an institutional repository, but not publicly through a Git remote repository. In this case, it is recommended to use <monospace>closed_data()</monospace>, and to manually upload the original <monospace>data.csv</monospace> file to the restricted access platform. If users wish to share their data through the Open Science Framework, it is sufficient to connect the OSF page to the Git remote repository as an <ext-link ext-link-type="uri" xlink:href="https://help.osf.io/hc/en-us/categories/360001550973-Add-ons">Add-on</ext-link>.</p>
</sec>
</sec>
<sec id="x1-20000-4.4">
<label>4.4.</label>
<title>Sharing code, research materials, design and analysis</title>
<p>When writing a manuscript created using dynamic document generation, analysis code is embedded in the prose of the paper. Thus, the TOP-guideline of sharing analysis code can be met simply by committing the source code of the manuscript to the Git repository, and making this remote repository Public. If authors additionally use open data and a reproducible environment (as suggested in WORCS), then a third party can simply replicate all analyses by copying the entire repository from the Git hosting service, and Knitting the manuscript on their local computer.</p>
<p>Aside from analysis code, the TOP-guidelines also encourage sharing new research materials, and details of the study design and analysis. These goals can be accomplished by placing any such documents in the Git repository folder, committing them, and pushing to a cloud hosting service. As with any document version controlled in this way, it is advisable (but not required) to use plain text only.</p>
</sec>
<sec id="x1-21000-4.5">
<label>4.5.</label>
<title>Preregistration</title>
<p>Lindsay et al. [<xref ref-type="bibr" rid="ref021">21</xref>] define preregistration as “creating a permanent record of your study plans before you look at the data. The plan is stored in a date-stamped, uneditable file in a secure online archive.” Two such archives are well-known in the social sciences: <ext-link ext-link-type="uri" xlink:href="https://aspredicted.org/">AsPredicted.org</ext-link>, and <ext-link ext-link-type="uri" xlink:href="https://osf.io/">OSF.io</ext-link>. However, Git cloud hosting services also conform to these standards. Thus, it is possible to preregister a study simply by committing a preregistration document to the local Git repository, and pushing it to the remote repository. Subsequently <ext-link ext-link-type="uri" xlink:href="https://docs.github.com/en/free-pro-team@latest/github/administering-a-repository/managing-releases-in-a-repository">taging the release</ext-link> as “Preregistration” on the remote repository renders it distinct from all other commits, and easily findable by people and programs. This approach is simple, quick, and robust. Moreover, it is compatible with formal preregistration through services such as <ext-link ext-link-type="uri" xlink:href="http://AsPredicted.org">AsPredicted.org</ext-link> or OSF.io: If the preregistration is written using dynamic document generation, as recommended in WORCS, this file can be rendered to PDF and uploaded as an attachment to the formal preregistration service.</p>
<p>The advantages, disadvantages, and pitfalls for preregistering different types of studies have been extensively debated elsewhere (see Lindsay et al. [<xref ref-type="bibr" rid="ref021">21</xref>]). For example, because the practice of preregistration has historically been closely tied to experimental research, it has been a matter of some debate whether secondary data analyses can be preregistered (but see Weston et al. [<xref ref-type="bibr" rid="ref043">43</xref>] for an excellent discussion of the topic).</p>
<p>When analyzing existing data, it is difficult to <italic>prove</italic> that a researcher did not have direct (or indirect, through collaborators or by reading studies using the same data) exposure to the data, before composing the preregistration. However, the question of proof is only relevant from a perspective of preventing scientific misconduct. Preregistration is a good way to ensure that a researcher is not “HARKing”: Hypothesizing after the results are known (Kerr [<xref ref-type="bibr" rid="ref017">17</xref>]).</p>
<p>Good faith preregistration efforts always improve the quality of deductive (theory-testing) research, because they avoid HARKing, ensure reliable significance tests, avoid overfitting noise in the data, and limit the number of forking paths researchers wander during data analysis (Gelman and Loken [<xref ref-type="bibr" rid="ref012">12</xref>]).</p>
<p>WORCS takes the pragmatic position that, in deductive (hypothesis-testing) research, it is beneficial to plan projects before executing them, to preregister these plans, and adhere to them. All deviations from this procedure should be disclosed. Researchers should minimize exposure to the data, and disclose any prior exposure, whether direct (e.g., by computing summary statistics) or indirect (e.g., by reading papers using the same data). Similarly, one can disclose any deviations from the analysis plan to handle unforeseen contingencies, such as violations of model assumptions; or additional exploratory analyses.</p>
<p>WORCS recommends documenting a verbal, conceptual description of the study plans in a text-based file. Optionally, an analysis script can be preregistered to document the planned analyses. If any changes must be made to the analysis code after obtaining the data, one can refer to the conceptual description to justify the changes. The ideal preregistered analysis script consists of a complete analysis that can be evaluated once the data are obtained. This ideal is often unattainable, because the data present researchers with unanticipated challenges; e.g., assumptions are violated, or analyses work differently than expected. Some of these challenges can be avoided by simulating the data one expects to obtain, and writing the analysis syntax based on the simulated data. This topic is beyond the scope of the present paper, but many user-friendly methods for simulating data are available in most statistical programming languages. For instance, <monospace>R</monospace> users can use the package <monospace>simstudy</monospace> (Goldfeld [<xref ref-type="bibr" rid="ref013">13</xref>]).</p>
<p>As soon as a project is preregistered on a Public Git repository, it is visible to the world, and reviewers (both formal reviewers designated by a journal, and informal reviewers recruited by other means) can submit comments, e.g., through “Pull requests” on a Git remote repository. If the remote repository is Private, Reviewers can be invited as “Collaborators”. It is important to note that contributing to the repository in any way will void reviewers’ anonymity, as their contributions will be linked to a user name. Private remote repositories can be made public at a later date, along with their entire time-stamped history and tagged releases.</p>
<sec id="x1-22000-4.5.1">
<label>4.5.1.</label>
<title>Implementation of preregistration in worcs</title>
<p>The <monospace>worcs</monospace> workflow facilitates preregistration, primarily by explicitly inviting a user to write the preregistration document. To this end, <monospace>worcs</monospace> imports several preregistration templates from the <monospace>R</monospace> package <monospace>prereg</monospace> (Aust [<xref ref-type="bibr" rid="ref006">6</xref>]), including templates from organizations like <ext-link ext-link-type="uri" xlink:href="http://AsPredicted.org">AsPredicted.org</ext-link> and <ext-link ext-link-type="uri" xlink:href="http://OSF.io">OSF.io</ext-link>, and from researchers (e.g., van ’t Veer and Giner-Sorolla [<xref ref-type="bibr" rid="ref042">42</xref>]). When initializing an RStudio project with the <monospace>worcs</monospace> project template, one of these preregistration templates can be selected, which will generate a file called <monospace>preregistration.Rmd</monospace>. This file should be used to document study plans, ideally prior to data collection. Within the workflow, the Git cloud hosting services can be used to preregister a study simply by pushing a text document with the study plans to a Git remote repository. By <ext-link ext-link-type="uri" xlink:href="https://docs.github.com/en/free-pro-team@latest/github/administering-a-repository/managing-releases-in-a-repository">tagging the commit</ext-link> as a preregistration (see <ext-link ext-link-type="uri" xlink:href="https://cjvanlissa.github.io/worcs/articles/workflow.html">the workflow vignette</ext-link>), it is distinct from all other commits, and easily findable by people and machines.</p>
</sec>
</sec>
<sec id="x1-23000-4.6">
<label>4.6.</label>
<title>Compatibility with other standards for open science</title>
<p>Aside from the TOP Guidelines, the FAIR Guiding Principles for scientific data management and stewardship (Wilkinson et al. [<xref ref-type="bibr" rid="ref045">45</xref>]) are an important standard for open science. These principles advocate that digital research objects should be Findable, Accessible, Interoperable and Reusable. Initially mainly promoted as principles for data, they are increasingly applied as a standard for other types of research output as well, most notably software (Lamprecht et al. [<xref ref-type="bibr" rid="ref019">19</xref>]).</p>
<p>WORCS was not designed to comprehensively address these principles, but the workflow does facilitate meeting them. In terms of Findability, all files in GitHub projects are searchable by content and meta-data, both on the platform and through standard search engines. The workflow further recommends that users create a project page on the Open Science Framework – a recognized repository in the social sciences. When doing so, it is important to generate a Digital Object Identifier (DOI) for this project. A DOI is a persistent way to identify and connect to an object on the internet, which is crucial for findability. Additional DOIs can be generated through the OSF for specific resources, such as data sets. It is further worth noting that, optionally, <ext-link ext-link-type="uri" xlink:href="https://guides.github.com/activities/citable-code/">GitHub repositories can be connected to Zenodo</ext-link>: On Zenodo, users can store a snapshot of the repository, provide metadata, and generate a DOI for the project or specific resources. When a project is connected to the OSF, as recommended, these steps may be redundant. Finally, each worcs project has a [YAML file] (<uri>https://yaml.org/</uri>) that lists the data objects (and other meta-data) in the project, which will allow web crawlers to index worcs projects. We use this metadata, for example, to identify public <monospace>worcs</monospace> projects on GitHub.</p>
<p>Accessibility is primarily safeguarded by hosting all project files in a public GitHub repository, which can be downloaded as a ZIP archive, and cloned or forked using the Git protocol. <ext-link ext-link-type="uri" xlink:href="https://archiveprogram.github.com/">GitHub is committed to long term accessibility of these resources</ext-link>. We further encourage users to make their data accessible when possible. When data must be closed, the <monospace>worcs</monospace> function <monospace>closed_data()</monospace> adds a paragraph to the project readme, indicating how readers can contact the author for access.</p>
<p>With regard to interoperability, the workflow recommends using plain-text files whenever possible, which ensures that code and meta-data are human- and machine-readable. Furthermore, the <monospace>worcs</monospace> package is implemented in R, which is open source. To promote reusability, we recommend users to specify an appropriate license for their projects. The <monospace>worcs</monospace> package includes the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/">Creative Commons (CC) licenses</ext-link>, and suggests a CC-BY 4.0 license by default. This license is featured in the GitHub repository, and we encourage users to also display it on their project’s OSF page. Note that it is possible to license specific project resources separately under different licenses. For instance, whereas the CC-licenses are suitable for data, media, and academic papers – they are ill-suited for licensing software. It is thus prudent to consider separately licensing specific project resources, particularly when a project contains <italic>original</italic> source code (i.e., you write your own functions). For a more extensive discussion of appropriate licensing, see Peikert and Brandmaier [<xref ref-type="bibr" rid="ref028">28</xref>], Stodden et al. [<xref ref-type="bibr" rid="ref038">38</xref>], and the website <ext-link ext-link-type="uri" xlink:href="https://choosealicense.com/">choosealicense.com</ext-link>.</p>
<p>To further facilitate reusability, <monospace>worcs</monospace> automatically generates a codebook for each data file. We encourage users to elaborate on the default codebook by adding variable description and categories, which would – in the future – enable indexing data by topic area.</p>
<p>Incidentally, the FAIR principles have been applied to software as well, and <monospace>worcs</monospace> follows these recommendations for <ext-link ext-link-type="uri" xlink:href="https://fair-software.eu/">FAIR research software</ext-link>. It is hosted on a version controlled public remote repository GitHub, has an open source licence (GPL v3.0), is registered in a community registry (CRAN), enables the citation of the software (using the <monospace>citation("worcs")</monospace> command, or by citing this paper), and followed the <ext-link ext-link-type="uri" xlink:href="https://bestpractices.coreinfrastructure.org/en"><italic>CII Best Practices</italic></ext-link> software quality checklist during development.</p>
<p>Sharing all research objects, as advocated in WORCS, also provides a thorough basis for research evaluation according to the San Francisco Declaration on Research Assessment (DORA; <uri>https://sfdora.org/</uri>), which plays an increasing role in grant funding, hiring, and promotion procedures. Direct access to research objects allows stakeholders to evaluate research quality based on content rather than relying on spurious surrogate indicators like journal impact factors, conference rankings, and h-indexes. The detailed version control and commit tracking of Git remote repositories furthermore make it possible to assess the relative contributions made by different researchers.</p>
</sec>
</sec>
<sec id="x1-24000-5">
<label>5.</label>
<title>Discussion</title>
<p>In this tutorial paper, we have presented a workflow for open reproducible code in science. The workflow aims to lower the threshold for grass-roots adoption of open science principles. The workflow is supported by an <monospace>R</monospace> package with an RStudio project template and convenience functions. This relatively light-weight workflow meets most of the requirements for open science as detailed in the TOP-guidelines, and is compatible with other open science guidelines. The workflow helps researchers meet existing requirements for open science, and to reap the benefits of working openly and reproducibly, even when such requirements are absent.</p>
<sec id="x1-25000-5.1">
<label>5.1.</label>
<title>Comparing WORCS to existing solutions</title>
<p>There have been several previous efforts to promote grass-roots adoption of open science principles. Each of these efforts has a different scope, strengths, and limitations that set it apart from WORCS. For example, there are “signalling solutions”; guidelines to structure and incentivize disclosure about open science practices. Specifically, Aalbersberg et al. [<xref ref-type="bibr" rid="ref001">1</xref>] suggested publishing a “TOP-statement” as supplemental material, which discloses the authors’ adherence to open science principles. Relatedly, Aczel et al. [<xref ref-type="bibr" rid="ref002">2</xref>] developed a consensus-based Transparency Checklist that authors can complete online to generate a report. Such signalling solutions are very easy to adopt, and they address TOP-guidelines 1–7. Many journals now also offer authors the opportunity to earn “badges” for adhering to open science guidelines (Kidwell et al. [<xref ref-type="bibr" rid="ref018">18</xref>]). These signalling solutions help structure authors’ disclosures about, and incentivize adherence to, open science practices. WORCS, too, has its own checklist that calls attention to a number of concrete items contributing to an open and reproducible research project. Users of the <monospace>worcs</monospace> package can receive a badge, displayed on the <monospace>README.md</monospace> file, based on a semi-automated scoring of the checklist items, by calling the function <monospace>check_worcs()</monospace> within a <monospace>worcs</monospace> project directory.</p>
<p>A different class of solutions instead focuses on the practical issue of <italic>how</italic> researchers can meet the requirements of open science. A notable example is the workflow for reproducible analyses developed by Peikert and Brandmaier [<xref ref-type="bibr" rid="ref028">28</xref>], which uses Docker to ensure strict computational reproducibility for even the most sophisticated analyses. There are some decisive differences with WORCS. First, concerning the scope of the workflow: WORCS is designed to address a unique issue not covered by other existing solutions, namely, to provide a workflow most conducive to satisfying TOP-guidelines 1–7 while adhering to the FAIR principles. Peikert and Brandmaier instead focus primarily on computational reproducibility, which is relevant for TOP-guidelines 2, 3, and 5. Second, with regard to ease of use, WORCS aims to bring down the learning curve by adopting sensible defaults for any decisions to be made. Peikert and Brandmaier, by contrast, designed their workflow to be very flexible and comprehensive, thus requiring substantially more background knowledge and technical sophistication from users. To sum up, WORCS builds upon the same general principles as Peikert and Brandmaier, and the two workflows are compatible. What sets WORCS apart is that it is more lightweight in terms of system and user requirements, thereby facilitating adoption, but still ensures computational reproducibility under <italic>most circumstances</italic>.</p>
<p>One initiative that WORCS is fully compatible with, is the <ext-link ext-link-type="uri" xlink:href="https://www.scientificpaperofthefuture.org/"><italic>Scientific Paper of the Future</italic></ext-link>. This organization encourages geoscientists to document data provenance and availability in public repositories, document software used, and document the analysis steps taken to derive the results. All of these goals could be met using WORCS.</p>
</sec>
<sec id="x1-26000-5.2">
<label>5.2.</label>
<title>Limitations</title>
<p>WORCS is intended to substantially reduce the threshold for adopting best practices in open and reproducible research. However, several limitations and issues for future development remain. One potential challenge is the learning curve associated with the tools outlined in this paper. Learning to work with <monospace>R</monospace>, RMarkdown, and Git takes time – although tutorials such as this one substantially reduce the learning curve. Moreover, the time investment tends to pay off. Working with <monospace>R</monospace> opens the door to many cutting edge analysis techniques. Working with RMarkdown saves time and prevents mistakes by avoiding tedious copying of results into a text document. Working with Git keeps projects organized, prevents accidental loss of work, enables integrating changes by collaborators in a non-destructive manner, and ensures that entire research projects are archived and can be accessed or copied by third parties. Thus, the time investment is eminently worthwhile.</p>
<p>Another limitation is the fact that no single workflow can suit all research projects. Not all projects conform to the steps outlined here; some may skip steps, add steps, or follow similar steps in a different order. In principle, WORCS does not enforce a linear order, and allows extentensive user flexibility. A related concern is that some projects might require specialized solutions outside of the scope of this paper. For example, some projects might use very large data files, rely on data that reside on a protected server, or use proprietary software dependencies that cannot be version controlled using <monospace>renv</monospace> or Docker. In such cases, the workflow can serve as a starting point for a custom approach; offering a primer on best practices, and a discussion of relevant factors to consider. We urge users to inform us of such challenges and custom solutions, so that we may add them to the <ext-link ext-link-type="uri" xlink:href="https://github.com/cjvanlissa/worcs">overview of WORCS-projects on GitHub</ext-link>, where they can serve as an example to others.</p>
<p>Another important challenge is managing collaborations when only the lead author uses RMarkdown, and the coauthors use Word. When using the <monospace>papaja</monospace> package to write APA-style papers, it is possible to Knit the manuscript to Word (.docx), by changing the line <monospace>output: papaja::apa6_pdf</monospace> in the manuscript’s YAML header to <monospace>output: papaja::apa6_docx</monospace>. There are some limitations to the conversion, discussed <ext-link ext-link-type="uri" xlink:href="https://crsh.github.io/papaja_man/limitations.html#microsoft-word-documents">here</ext-link>. When soliciting feedback from co-authors, ask them to use Track Changes and comment bubbles in Word. Then, manually incorporate their changes into the <monospace>manuscript.Rmd</monospace> file. In most cases, this is the most user-friendly approach, as most lead authors would review changes by co-authors anyway. A second approach is to ask collaborators to work in plain text. In this case, send collaborators the <monospace>manuscript.Rmd</monospace> file, and ask them to open (and save) it in Word or Notepad as a plain text file. When they send it back, make sure any changes to your local file are committed, and then simply overwrite your local version with their file. In RStudio, select the file in the Git tab, and click the Diff button to examine what changes the collaborator has made relative to your last committed version.</p>
<p>If all collaborators are committed to using WORCS, they can <ext-link ext-link-type="uri" xlink:href="https://help.github.com/en/github/getting-started-with-github/fork-a-repo">Fork the repository</ext-link> from the lead author on GitHub, <ext-link ext-link-type="uri" xlink:href="https://help.github.com/en/github/creating-cloning-and-archiving-repositories/cloning-a-repository">clone it to their local device</ext-link>, make their own changes, and <ext-link ext-link-type="uri" xlink:href="https://help.github.com/en/github/collaborating-with-issues-and-pull-requests/creating-a-pull-request">send a pull request</ext-link> to incorporate their changes. Working this way is extremely conducive to scientific collaboration (Ram [<xref ref-type="bibr" rid="ref032">32</xref>]). Recall that, when using Git for collaborative writing, it is recommended to insert a line break after every sentence so that the change log will indicate which specific sentence was edited, and to prevent <ext-link ext-link-type="uri" xlink:href="https://help.github.com/en/github/collaborating-with-issues-and-pull-requests/resolving-a-merge-conflict-on-github">“merge conflicts”</ext-link> when two authors edit the same line. The resulting document will be rendered to PDF without spurious line breaks.</p>
<p>Being familiar with Git remote repositories opens doors to new forms of collaboration: In the open source software community, continuous peer review and voluntary collaborative acts by strangers who are interested in a project are commonplace (see Adolph et al. [<xref ref-type="bibr" rid="ref003">3</xref>]). This kind of collaboration is budding in scientific software development as well; for example, the lead author of this paper became a co-author on several <monospace>R</monospace> packages after submitting pull requests with bug fixes or additional functionality (Hallquist et al. [<xref ref-type="bibr" rid="ref015">15</xref>]; Rosenberg et al. [<xref ref-type="bibr" rid="ref034">34</xref>]), and two co-authors of this paper became involved by contributing pull requests to <monospace>worcs</monospace>. It is also possible to invite such collaboration by <ext-link ext-link-type="uri" xlink:href="https://help.github.com/en/github/managing-your-work-on-github/about-issues">opening Issues</ext-link> for tasks that still need to be accomplished, and tag known collaborators to address them, or invite external collaborators to contribute their expertise.</p>
<p>A final limitation is that, as WORCS is relatively new, the number of current users is still limited. We therefore do not have elaborate insights in user experiences or feedback. We strive to make the uptake of worcs as easy as possible, by means of this background paper, extensive documentation and vignettes for the <monospace>R</monospace> implementation, <ext-link ext-link-type="uri" xlink:href="https://www.youtube.com/playlist?list=PLOQIOFZl7uYbTgVdUee9n3eebMNmJtV9y">online video tutorials</ext-link>, webinars and <ext-link ext-link-type="uri" xlink:href="https://github.com/cjvanlissa/worcs/tree/master#adoption-of-worcs-by-users">exemplar use cases</ext-link>. We encourage our users to provide us with feedback, feature requests, or bug reports through the channels <ext-link ext-link-type="uri" xlink:href="https://github.com/cjvanlissa/worcs/tree/master#contributing-and-contact-information">indicated here</ext-link>.</p>
</sec>
<sec id="x1-27000-5.3">
<label>5.3.</label>
<title>Future developments</title>
<p>WORCS provides a user-friendly and lightweight workflow for open, reproducible research, that meets all TOP-guidelines pertaining to reproducibility (1–7). Nevertheless, there are clear directions for future developments. Firstly, although the workflow is currently implemented only in <monospace>R</monospace>, it is conceptually relevant for users of other statistical programming languages, and we welcome efforts to implement WORCS in other platforms. We welcome efforts to implement WORCS in other platforms. Secondly, even when a project is in <monospace>R</monospace>, it may have dependencies outside of the <monospace>R</monospace> environment that cannot be managed using <monospace>renv</monospace>. It is beyond the scope of the <monospace>worcs</monospace> package to support tools outside of <monospace>R</monospace>, or to containerize a project so that it can be identically reinstated on a different system or virtual machine. The forthcoming package <monospace>repro</monospace> (Peikert et al. [<xref ref-type="bibr" rid="ref029">29</xref>]) will offer such extensions of the workflow, thus combining the strengths of WORCS with the solutions proposed by Peikert and Brandmaier [<xref ref-type="bibr" rid="ref028">28</xref>].</p>
</sec>
<sec id="x1-28000-5.4">
<label>5.4.</label>
<title>Conclusion</title>
<p>WORCS offers a workflow for open reproducible code in science. The step-by-step procedure outlined in this tutorial helps researchers make an entire research project Open and Reproducible. The accompanying <monospace>R</monospace> package provides user-friendly support functions for several steps in the workflow, and an RStudio project template to get the project set up correctly.</p>
<p>WORCS encourages and simplifies the adoption of open science principles in daily scientific work. It helps researchers make all research output created throughout the scientific process – not just manuscripts, but data, code, and methods – open and publicly assessible. This enables other researchers to reproduce results, and facilitates cumulative science by allowing others to make direct use of these research objects.</p>
</sec>
</sec>
</body>
<back>
<ack>
<title>Acknowledgements</title>
<p>The lead author is supported by a NWO Veni grant (NWO grant number VI.Veni.191G.090). We acknowledge Jeroen Ooms for offering feedback and suggesting the use of the R package gert.</p></ack>
<ref-list>
<title>References</title>
<ref id="ref001">
<label>[1]</label><mixed-citation publication-type="other"><string-name><given-names>I.J.</given-names> <surname>Aalbersberg</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Appleyard</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Brookhart</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Carpenter</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Clarke</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Curry</surname></string-name> <etal>et al.</etal>, Making science transparent by default; introducing the TOP statement, 2018. doi:<pub-id pub-id-type="doi">10.31219/osf.io/sm78t</pub-id>.</mixed-citation>
</ref>
<ref id="ref002">
<label>[2]</label><mixed-citation publication-type="journal"><string-name><given-names>B.</given-names> <surname>Aczel</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Szaszi</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Sarafoglou</surname></string-name>, <string-name><given-names>Z.</given-names> <surname>Kekecs</surname></string-name>, <string-name><given-names>Š.</given-names> <surname>Kucharský</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Benjamin</surname></string-name> <etal>et al.</etal>, <article-title>A consensus-based transparency checklist</article-title>, <source>Nature Human Behaviour</source> (<year>2019</year>), <fpage>1</fpage>–<lpage>3</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41562-019-0772-6</pub-id>.</mixed-citation>
</ref>
<ref id="ref003">
<label>[3]</label><mixed-citation publication-type="journal"><string-name><given-names>K.E.</given-names> <surname>Adolph</surname></string-name>, <string-name><given-names>R.O.</given-names> <surname>Gilmore</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Freeman</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Sanderson</surname></string-name> and <string-name><given-names>D.</given-names> <surname>Millman</surname></string-name>, <article-title>Toward open behavioral science</article-title>, <source>Psychological Inquiry</source> <volume>23</volume>(<issue>3</issue>) (<year>2012</year>), <fpage>244</fpage>–<lpage>247</lpage>. doi:<pub-id pub-id-type="doi">10.1080/1047840X.2012.705133</pub-id>.</mixed-citation>
</ref>
<ref id="ref004">
<label>[4]</label><mixed-citation publication-type="other"><string-name><given-names>J.</given-names> <surname>Allaire</surname></string-name>, <string-name><given-names>Y.</given-names> <surname>Xie</surname></string-name>, <collab>R Foundation</collab>, <string-name><given-names>H.</given-names> <surname>Wickham</surname></string-name>, <collab>Journal of Statistical Software</collab> <string-name><given-names>R.</given-names> <surname>Vaidyanathan</surname></string-name> <etal>et al.</etal>Rticles: Article formats for r markdown 2020, Retrieved from <uri>https://CRAN.R-project.org/package=rticles</uri>.</mixed-citation>
</ref>
<ref id="ref005">
<label>[5]</label><mixed-citation publication-type="other"><string-name><given-names>J.J.</given-names> <surname>Allaire</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Ushey</surname></string-name>, <collab>RStudio</collab> and <string-name><given-names>Y.</given-names> <surname>Tang</surname></string-name>, R Markdown Python engine, 2020, Retrieved January 13, 2020, from <uri>https://rstudio.github.io/reticulate/articles/r_markdown.html</uri>.</mixed-citation>
</ref>
<ref id="ref006">
<label>[6]</label><mixed-citation publication-type="other"><string-name><given-names>F.</given-names> <surname>Aust</surname></string-name>, Prereg: R Markdown templates to preregister scientific studies (version 0.4.0), 2019, Retrieved from <uri>https://CRAN.R-project.org/package=prereg</uri>.</mixed-citation>
</ref>
<ref id="ref007">
<label>[7]</label><mixed-citation publication-type="other"><string-name><given-names>F.</given-names> <surname>Aust</surname></string-name> and <string-name><given-names>M.</given-names> <surname>Barth</surname></string-name>, Papaja: Prepare reproducible APA journal articles with R Markdown, 2020, (Version 0.1.0.9842), (Original work published 2014), Retrieved from <uri>https://github.com/crsh/papaja</uri>.</mixed-citation>
</ref>
<ref id="ref008">
<label>[8]</label><mixed-citation publication-type="other"><string-name><given-names>S.</given-names> <surname>Bezjak</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Clyburne-Sherin</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Conzett</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Fernandes</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Görögh</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Helbig</surname></string-name> <etal>et al.</etal>, Open science training handbook (Version 1.0). Zenodo, 2018. doi:<pub-id pub-id-type="doi">10.5281/zenodo.1212496</pub-id>.</mixed-citation>
</ref>
<ref id="ref009">
<label>[9]</label><mixed-citation publication-type="other"><string-name><given-names>J.D.</given-names> <surname>Blischak</surname></string-name>, <string-name><given-names>E.R.</given-names> <surname>Davenport</surname></string-name> and <string-name><given-names>G.</given-names> <surname>Wilson</surname></string-name>, <article-title>A quick introduction to version control with Git and GitHub</article-title>, <source>PLOS Computational Biology</source> <volume>12</volume>(<issue>1</issue>) (<year>2016</year>), <elocation-id>e1004668</elocation-id>. doi:<pub-id pub-id-type="doi">10.1371/journal.pcbi.1004668</pub-id>.</mixed-citation>
</ref>
<ref id="ref010">
<label>[10]</label><mixed-citation publication-type="other"><string-name><given-names>C.T.</given-names> <surname>Brown</surname></string-name>, How I learned to stop worrying and love the coming archivability crisis in scientific software, 2017, Retrieved January 13, 2020, from <uri>http://ivory.idyll.org/blog/2017-pof-software-archivability.html</uri>.</mixed-citation>
</ref>
<ref id="ref011">
<label>[11]</label><mixed-citation publication-type="other"><string-name><given-names>J.C.</given-names> <surname>Coyne</surname></string-name>, <article-title>Replication initiatives will not salvage the trustworthiness of psychology</article-title>, <source>BMC Psychology</source> <volume>4</volume>(<issue>1</issue>) (<year>2016</year>), <elocation-id>28</elocation-id>. doi:<pub-id pub-id-type="doi">10.1186/s40359-016-0134-3</pub-id>.</mixed-citation>
</ref>
<ref id="ref012">
<label>[12]</label><mixed-citation publication-type="journal"><string-name><given-names>A.</given-names> <surname>Gelman</surname></string-name> and <string-name><given-names>E.</given-names> <surname>Loken</surname></string-name>, <article-title>The statistical crisis in science: Data-dependent analysis – a “Garden of forking paths” – explains why many statistically significant comparisons don’t hold up</article-title>, <source>American Scientist</source> <volume>102</volume>(<issue>6</issue>) (<year>2014</year>), <fpage>460</fpage>–<lpage>466</lpage>, <comment>Retrieved from <uri>https://go.gale.com/ps/i.do?p=AONE&amp;sw=w&amp;issn=00030996&amp;v=2.1&amp;it=r&amp;id=GALE%7CA389260653&amp;sid=googleScholar&amp;linkaccess=abs</uri></comment>. doi:<pub-id pub-id-type="doi">10.1511/2014.111.460</pub-id>.</mixed-citation>
</ref>
<ref id="ref013">
<label>[13]</label><mixed-citation publication-type="other"><string-name><given-names>K.</given-names> <surname>Goldfeld</surname></string-name>, Simstudy: Simulation of study data, 2020, Retrieved from <uri>https://CRAN.R-project.org/package=simstudy</uri>.</mixed-citation>
</ref>
<ref id="ref014">
<label>[14]</label><mixed-citation publication-type="other"><string-name><given-names>G.</given-names> <surname>Grolemund</surname></string-name> and <string-name><given-names>H.</given-names> <surname>Wickham</surname></string-name>, <source>R for Data Science</source>, <publisher-name>O’Reilly</publisher-name>, <year>2017</year>, <comment>Retrieved from <uri>https://r4ds.had.co.nz/</uri>.</comment></mixed-citation>
</ref>
<ref id="ref015">
<label>[15]</label><mixed-citation publication-type="other"><string-name><given-names>M.</given-names> <surname>Hallquist</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Wiley</surname></string-name> and <string-name><given-names>C.J.</given-names> <surname>Van Lissa</surname></string-name>, MplusAutomation: An R package for facilitating large-scale latent variable analyses in Mplus (Version 0.7-3), 2018, Retrieved from <uri>https://CRAN.R-project.org/package=MplusAutomation</uri>.</mixed-citation>
</ref>
<ref id="ref016">
<label>[16]</label><mixed-citation publication-type="journal"><string-name><given-names>L.K.</given-names> <surname>John</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Loewenstein</surname></string-name> and <string-name><given-names>D.</given-names> <surname>Prelec</surname></string-name>, <article-title>Measuring the prevalence of questionable research practices with incentives for truth telling</article-title>, <source>Psychological Science</source> <volume>23</volume>(<issue>5</issue>) (<year>2012</year>), <fpage>524</fpage>–<lpage>532</lpage>. doi:<pub-id pub-id-type="doi">10.1177/0956797611430953</pub-id>.</mixed-citation>
</ref>
<ref id="ref017">
<label>[17]</label><mixed-citation publication-type="journal"><string-name><given-names>N.L.</given-names> <surname>Kerr</surname></string-name>, <article-title>HARKing: Hypothesizing after the results are known</article-title>, <source>Personality and Social Psychology Review: An Official Journal of the Society for Personality and Social Psychology, Inc</source> <volume>2</volume>(<issue>3</issue>) (<year>1998</year>), <fpage>196</fpage>–<lpage>217</lpage>. doi:<pub-id pub-id-type="doi">10.1207/s15327957pspr0203_4</pub-id>.</mixed-citation>
</ref>
<ref id="ref018">
<label>[18]</label><mixed-citation publication-type="other"><string-name><given-names>M.C.</given-names> <surname>Kidwell</surname></string-name>, <string-name><given-names>L.B.</given-names> <surname>Lazarević</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Baranski</surname></string-name>, <string-name><given-names>T.E.</given-names> <surname>Hardwicke</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Piechowski</surname></string-name>, <string-name><given-names>L.-S.</given-names> <surname>Falkenberg</surname></string-name> and <string-name><given-names>B.A.</given-names> <surname>Nosek</surname></string-name>, <article-title>Badges to acknowledge open practices: A simple, low-cost, effective method for increasing transparency</article-title>, <source>PLOS Biology</source> <volume>14</volume>(<issue>5</issue>) (<year>2016</year>), <elocation-id>e1002456</elocation-id>. doi:<pub-id pub-id-type="doi">10.1371/journal.pbio.1002456</pub-id>.</mixed-citation>
</ref>
<ref id="ref019">
<label>[19]</label><mixed-citation publication-type="journal"><string-name><given-names>A.-L.</given-names> <surname>Lamprecht</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Garcia</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Kuzak</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Martinez</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Arcila</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Martin Del Pico</surname></string-name> <etal>et al.</etal>, <article-title>Towards FAIR principles for research software</article-title>, <source>Data Science</source> (<year>2019</year>), <fpage>1</fpage>–<lpage>23</lpage>. doi:<pub-id pub-id-type="doi">10.3233/DS-190026</pub-id>.</mixed-citation>
</ref>
<ref id="ref020">
<label>[20]</label><mixed-citation publication-type="other"><string-name><given-names>W.J.M.</given-names> <surname>Levelt</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Noort</surname></string-name> and <string-name><given-names>P.J.D.</given-names> <surname>Drenth</surname></string-name>, Failing science: The fraudulent research practices of social psychologist Diederik Stapel (Falende wetenschap: De frauduleuze onderzoekspraktijken van sociaal-psycholoog Diederik Stapel), 2012, Retrieved from <uri>https://www.onderwijsbrabant.nl/sites/default/files/eindrapport_stapel_nov_2012.pdf</uri>.</mixed-citation>
</ref>
<ref id="ref021">
<label>[21]</label><mixed-citation publication-type="other"><string-name><given-names>D.S.</given-names> <surname>Lindsay</surname></string-name>, <string-name><given-names>D.J.</given-names> <surname>Simons</surname></string-name> and <string-name><given-names>S.O.</given-names> <surname>Lilienfeld</surname></string-name>, <article-title>Research preregistration 101</article-title>, <source>APS Observer</source> <volume>29</volume>(<issue>10</issue>) (<year>2016</year>), Retrieved from <uri>https://www.psychologicalscience.org/observer/research-preregistration-101</uri>.</mixed-citation>
</ref>
<ref id="ref022">
<label>[22]</label><mixed-citation publication-type="other"><string-name><given-names>R.A.</given-names> <surname>Muenchen</surname></string-name>, The popularity of data science software, 2012, April 25, Retrieved January 8, 2020, from <uri>http://r4stats.com/articles/popularity/</uri>.</mixed-citation>
</ref>
<ref id="ref023">
<label>[23]</label><mixed-citation publication-type="journal"><string-name><given-names>B.A.</given-names> <surname>Nosek</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Alter</surname></string-name>, <string-name><given-names>G.C.</given-names> <surname>Banks</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Borsboom</surname></string-name>, <string-name><given-names>S.D.</given-names> <surname>Bowman</surname></string-name>, <string-name><given-names>S.J.</given-names> <surname>Breckler</surname></string-name> <etal>et al.</etal>, <article-title>Promoting an open research culture</article-title>, <source>Science</source> <volume>348</volume>(<issue>6242</issue>) (<year>2015</year>), <fpage>1422</fpage>–<lpage>1425</lpage>. doi:<pub-id pub-id-type="doi">10.1126/science.aab2374</pub-id>.</mixed-citation>
</ref>
<ref id="ref024">
<label>[24]</label><mixed-citation publication-type="journal"><string-name><given-names>B.A.</given-names> <surname>Nosek</surname></string-name> and <string-name><given-names>Y.</given-names> <surname>Bar-Anan</surname></string-name>, <article-title>Scientific utopia: I. Opening scientific communication</article-title>, <source>Psychological Inquiry</source> <volume>23</volume>(<issue>3</issue>) (<year>2012</year>), <fpage>217</fpage>–<lpage>243</lpage>. doi:<pub-id pub-id-type="doi">10.1080/1047840X.2012.692215</pub-id>.</mixed-citation>
</ref>
<ref id="ref025">
<label>[25]</label><mixed-citation publication-type="journal"><string-name><given-names>B.</given-names> <surname>Nowok</surname></string-name>, <string-name><given-names>G.M.</given-names> <surname>Raab</surname></string-name> and <string-name><given-names>C.</given-names> <surname>Dibben</surname></string-name>, <article-title>Synthpop: Bespoke creation of synthetic data in R</article-title>, <source>Journal of Statistical Software</source> <volume>74</volume>(<issue>1,1</issue>) (<year>2016</year>), <fpage>1</fpage>–<lpage>26</lpage>. doi:<pub-id pub-id-type="doi">10.18637/jss.v074.i11</pub-id>.</mixed-citation>
</ref>
<ref id="ref026">
<label>[26]</label><mixed-citation publication-type="other"><string-name><given-names>J.</given-names> <surname>Ooms</surname></string-name>, Gert: Simple Git client for r, 2019, Retrieved from <uri>https://CRAN.R-project.org/package=gert</uri>.</mixed-citation>
</ref>
<ref id="ref027">
<label>[27]</label><mixed-citation publication-type="journal"><string-name><given-names>P.</given-names> <surname>Patil</surname></string-name>, <string-name><given-names>R.D.</given-names> <surname>Peng</surname></string-name> and <string-name><given-names>J.T.</given-names> <surname>Leek</surname></string-name>, <article-title>A visual tool for defining reproducibility and replicability</article-title>, <source>Nature Human Behaviour</source> <volume>3</volume>(<issue>7,7</issue>) (<year>2019</year>), <fpage>650</fpage>–<lpage>652</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41562-019-0629-z</pub-id>.</mixed-citation>
</ref>
<ref id="ref028">
<label>[28]</label><mixed-citation publication-type="other"><string-name><given-names>A.</given-names> <surname>Peikert</surname></string-name> and <string-name><given-names>A.M.</given-names> <surname>Brandmaier</surname></string-name>, A reproducible data analysis workflow with R Markdown, Git, Make, and Docker. doi:<pub-id pub-id-type="doi">10.31234/osf.io/8xzqy</pub-id>.</mixed-citation>
</ref>
<ref id="ref029">
<label>[29]</label><mixed-citation publication-type="other"><string-name><given-names>A.</given-names> <surname>Peikert</surname></string-name>, <string-name><given-names>A.M.</given-names> <surname>Brandmaier</surname></string-name> and <string-name><given-names>C.J.</given-names> <surname>Van Lissa</surname></string-name>, Repro: Automated setup of reproducible workflows and their dependencies, 2020, Retrieved from <uri>https://github.com/aaronpeikert/repro</uri>.</mixed-citation>
</ref>
<ref id="ref030">
<label>[30]</label><mixed-citation publication-type="journal"><string-name><given-names>M.</given-names> <surname>Phillips</surname></string-name> and <string-name><given-names>B.M.</given-names> <surname>Knoppers</surname></string-name>, <article-title>The discombobulation of de-identification</article-title>, <source>Nature Biotechnology</source> <volume>34</volume>(<issue>11,11</issue>) (<year>2016</year>), <fpage>1102</fpage>–<lpage>1103</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nbt.3696</pub-id>.</mixed-citation>
</ref>
<ref id="ref031">
<label>[31]</label><mixed-citation publication-type="other"><collab>R Core Team</collab>, <source>R: A Language and Environment for Statistical Computing</source>, <publisher-name>R Foundation for Statistical Computing</publisher-name>, <publisher-loc>Vienna, Austria</publisher-loc>, <year>2020</year>. <comment>Retrieved from <uri>https://www.R-project.org/</uri></comment>.</mixed-citation>
</ref>
<ref id="ref032">
<label>[32]</label><mixed-citation publication-type="other"><string-name><given-names>K.</given-names> <surname>Ram</surname></string-name>, <article-title>Git can facilitate greater reproducibility and increased transparency in science</article-title>, <source>Source Code for Biology and Medicine</source> <volume>8</volume>(<issue>1</issue>) (<year>2013</year>), <elocation-id>7</elocation-id>. doi:<pub-id pub-id-type="doi">10.1186/1751-0473-8-7</pub-id>.</mixed-citation>
</ref>
<ref id="ref033">
<label>[33]</label><mixed-citation publication-type="other"><string-name><given-names>R.</given-names> <surname>Rivest</surname></string-name>, The MD5 message-digest algorithm, MIT Laboratory for Computer Science and RSA Data Security, Inc., 1992. Available at: <uri>https://doi.org/10.17487/RFC1321</uri>.</mixed-citation>
</ref>
<ref id="ref034">
<label>[34]</label><mixed-citation publication-type="other"><string-name><given-names>J.</given-names> <surname>Rosenberg</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Beymer</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Anderson</surname></string-name>, <string-name><given-names>C.J.</given-names> <surname>Van Lissa</surname></string-name> and <string-name><given-names>J.</given-names> <surname>Schmidt</surname></string-name>, <article-title>tidyLPA: An R package to easily carry out latent profile analysis (LPA) using open-source or commercial software</article-title>, <source>Journal of Open Source Software</source> <volume>3</volume>(<issue>30</issue>) (<year>2018</year>), <elocation-id>978</elocation-id>. doi:<pub-id pub-id-type="doi">10.21105/joss.00978</pub-id>.</mixed-citation>
</ref>
<ref id="ref035">
<label>[35]</label><mixed-citation publication-type="other"><collab>RStudio Team</collab>, <source>RStudio: Integrated Development Environment for R</source>, <publisher-name>RStudio, Inc.</publisher-name>, <publisher-loc>Boston, MA</publisher-loc>, <year>2015</year>. <comment>Retrieved from <uri>http://www.rstudio.com/</uri>.</comment></mixed-citation>
</ref>
<ref id="ref036">
<label>[36]</label><mixed-citation publication-type="journal"><string-name><given-names>P.E.</given-names> <surname>Shrout</surname></string-name> and <string-name><given-names>J.L.</given-names> <surname>Rodgers</surname></string-name>, <article-title>Psychology, science, and knowledge construction: Broadening perspectives from the replication crisis</article-title>, <source>Annual Review of Psychology</source> <volume>69</volume>(<issue>1</issue>) (<year>2018</year>), <fpage>487</fpage>–<lpage>510</lpage>. doi:<pub-id pub-id-type="doi">10.1146/annurev-psych-122216-011845</pub-id>.</mixed-citation>
</ref>
<ref id="ref037">
<label>[37]</label><mixed-citation publication-type="other"><string-name><given-names>J.</given-names> <surname>Sondervan</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Bosman</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Kramer</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Brinkman</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Imming</surname></string-name> and <string-name><given-names>A.</given-names> <surname>Versteeg</surname></string-name>, The COVID-19 pandemic stresses the societal importance of open science, <italic>ScienceGuide</italic>, 2020, April 3, Retrieved from <uri>https://www.scienceguide.nl/2020/04/dire-times-of-covid-19-stress-the-societal-importance-of-open-science/</uri>.</mixed-citation>
</ref>
<ref id="ref038">
<label>[38]</label><mixed-citation publication-type="journal"><string-name><given-names>V.</given-names> <surname>Stodden</surname></string-name>, <string-name><given-names>M.</given-names> <surname>McNutt</surname></string-name>, <string-name><given-names>D.H.</given-names> <surname>Bailey</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Deelman</surname></string-name>, <string-name><given-names>Y.</given-names> <surname>Gil</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Hanson</surname></string-name> <etal>et al.</etal>, <article-title>Enhancing reproducibility for computational methods</article-title>, <source>Science</source> <volume>354</volume>(<issue>6317</issue>) (<year>2016</year>), <fpage>1240</fpage>–<lpage>1241</lpage>. doi:<pub-id pub-id-type="doi">10.1126/science.aah6168</pub-id>.</mixed-citation>
</ref>
<ref id="ref039">
<label>[39]</label><mixed-citation publication-type="other"><string-name><given-names>J.</given-names> <surname>Tennant</surname></string-name>, Open science is just good science, 2018, TU Delft, Retrieved from <uri>https://figshare.com/articles/Open_Science_is_just_good_science_pptx/5783004</uri>.</mixed-citation>
</ref>
<ref id="ref040">
<label>[40]</label><mixed-citation publication-type="other"><string-name><given-names>K.</given-names> <surname>Ushey</surname></string-name>, 2020, Renv: Project environments (Version 0.12.0). Retrieved from <uri>https://CRAN.R-project.org/package=renv</uri>.</mixed-citation>
</ref>
<ref id="ref041">
<label>[41]</label><mixed-citation publication-type="other"><string-name><given-names>C.J.</given-names> <surname>Van Lissa</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Peikert</surname></string-name> and <string-name><given-names>A.M.</given-names> <surname>Brandmaier</surname></string-name>, Worcs: Workflow for open reproducible code in science (Version 0.1.5), 2020, Retrieved from <uri>https://cran.r-project.org/web/packages/worcs/index.html</uri>.</mixed-citation>
</ref>
<ref id="ref042">
<label>[42]</label><mixed-citation publication-type="journal"><string-name><given-names>A.E.</given-names> <surname>van ’t Veer</surname></string-name> and <string-name><given-names>R.</given-names> <surname>Giner-Sorolla</surname></string-name>, <article-title>Pre-registration in social psychology – a discussion and suggested template</article-title>, <source>Journal of Experimental Social Psychology</source> <volume>67</volume> (<year>2016</year>), <fpage>2</fpage>–<lpage>12</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.jesp.2016.03.004</pub-id>.</mixed-citation>
</ref>
<ref id="ref043">
<label>[43]</label><mixed-citation publication-type="other"><string-name><given-names>S.J.</given-names> <surname>Weston</surname></string-name>, <string-name><given-names>S.J.</given-names> <surname>Ritchie</surname></string-name>, <string-name><given-names>J.M.</given-names> <surname>Rohrer</surname></string-name> and <string-name><given-names>A.K.</given-names> <surname>Przybylski</surname></string-name>, <article-title>Recommendations for increasing the transparency of analysis of preexisting data sets</article-title>, <source>Advances in Methods and Practices in Psychological Science</source> (<year>2019</year>). doi:<pub-id pub-id-type="doi">10.1177/2515245919848684</pub-id>.</mixed-citation>
</ref>
<ref id="ref044">
<label>[44]</label><mixed-citation publication-type="journal"><string-name><given-names>H.</given-names> <surname>Wickham</surname></string-name>, <article-title>Tidy data</article-title>, <source>Journal of Statistical Software</source> <volume>59</volume>(<issue>1,1</issue>) (<year>2014</year>), <fpage>1</fpage>–<lpage>23</lpage>. doi:<pub-id pub-id-type="doi">10.18637/jss.v059.i10</pub-id>.</mixed-citation>
</ref>
<ref id="ref045">
<label>[45]</label><mixed-citation publication-type="other"><string-name><given-names>M.D.</given-names> <surname>Wilkinson</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Dumontier</surname></string-name>, <string-name><given-names>I.J.</given-names> <surname>Aalbersberg</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Appleton</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Axton</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Baak</surname></string-name> <etal>et al.</etal>, <article-title>The FAIR guiding principles for scientific data management and stewardship</article-title>, <source>Scientific Data</source> <volume>3</volume>(<issue>1</issue>) (<year>2016</year>), <elocation-id>160018</elocation-id>. doi:<pub-id pub-id-type="doi">10.1038/sdata.2016.18</pub-id>.</mixed-citation>
</ref>
<ref id="ref046">
<label>[46]</label><mixed-citation publication-type="other"><string-name><given-names>M.N.</given-names> <surname>Wright</surname></string-name> and <string-name><given-names>A.</given-names> <surname>Ziegler</surname></string-name>, Ranger: A fast implementation of random forests for high dimensional data in C++ and R, 2015, August 18, Retrieved from <uri>http://arxiv.org/abs/1508.04409</uri>.</mixed-citation>
</ref>
<ref id="ref047">
<label>[47]</label><mixed-citation publication-type="other"><string-name><given-names>Y.</given-names> <surname>Xie</surname></string-name>, <string-name><given-names>J.J.</given-names> <surname>Allaire</surname></string-name> and <string-name><given-names>G.</given-names> <surname>Grolemund</surname></string-name>, <source>R Markdown: The Definitive Guide</source>, <publisher-name>Chapman and Hall/CRC</publisher-name>, <year>2018</year>. <comment>Retrieved from <uri>https://bookdown.org/yihui/rmarkdown/</uri></comment>.</mixed-citation>
</ref>
</ref-list>
</back>
</article>
