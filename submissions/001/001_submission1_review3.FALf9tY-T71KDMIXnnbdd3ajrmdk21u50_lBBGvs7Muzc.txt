Review by Olivia Woolley Meza (http://orcid.org/0000-0003-4517-2765)

Overall impression *:

- Average


Suggested decision *:

- Undecided


Reviewer's confidence *:

- High


Significance (Does the work address an important problem within the research
fields covered by the journal?) *:

- Moderate significance


Background (Is the work appropriately based on and connected to the relevant
related work?) *:

- Reasonable


Novelty (For research papers: Does the work provide new insights or new methods
of a substantial kind? For position papers: Does the work provide a novel and
potentially disruptive view on the given topic? For survey papers: Does the work
provide an overview that is unique in its scope or structure for the given
topic?) *:

- Limited novelty


Technical quality (For research papers: Are the methods adequate for the
addressed problem, are they correctly and thoroughly applied, and are their
results interpreted in a sound manner? For position papers: Is the advocated
position supported by sound and thorough arguments? For survey papers: Is the
topic covered in a comprehensive and well balanced manner, are the covered
approaches accurately described and compared, and are they placed in a
convincing common framework?) *:

- Weak


Presentation (Are the text, figures, and tables of the work accessible, pleasant
to read, clearly structured, and free of major errors in grammar or style?) *:

- Average


Length of the manuscript *?

- The length of this manuscript is about right

Data availability *:

- Not all used and produced data are FAIR and openly available in established
  data repositories; authors need to fix this

Summary of paper in a few sentences *:

The author studies the activity of extremist groups, specifically ISIS, on the Twitter microblogging platform. Accounts are manually identified as associated with extremist ISIS related content. The tweets, retweets and mentions generated by these 25 thousand ISIS supporters are obtained for the period of January 2014 to June 2015, together with their followers and friends. Using this dataset, different analyses are performed to characterize spreading of extremist information and identify different types of information spreading strategies. 

Reasons to accept *:
The spread of radical (non-true) information is clearly an important and germane topic. The use of manually verified extremist accounts is, as the author highlights, a good and uncommon practice in understanding  information spread. There are initial indications of interesting systematic variation in the effectiveness of different user "types" at spreading extremist information.

Reasons to reject *:
Unfortunately the analysis is underdeveloped, staying on a purely descriptive level. More importantly, there are technical issues that need to be addressed in order to asses whether the  results are correct and meaningful. Lastly, it is not clear to me that this stands as a unified position paper, it is rather half a position paper and half a research paper combined, but not reaching the necessary standard or depth for either. I discuss below in more detail. 

Further comments:
Undoubtedly this paper addresses an important topic, unfortunately I see a number of problems that mean it is not yet ready for publication. 
The first issue is that I am not sure this is a position paper -- it seems to fall more into the are of a research paper, but for this it lacks sufficient rigor, depth of analysis and interpretation. Perhaps I am missing the point, but I think that the author has to make it clearer how the more novel an interesting part of the approach, namely using a manually verified list of accounts on Twitter that can be linked to ISIS, is adding substantive new insight to our understanding of how extremist information can spread online. 
Q1 and Q2 are not specific enough research questions to unify the content of the piece -- currently the introduction, addressing Q1 mainly,  reads more like a position piece, and is disconnected from the analysis which addresses Q2 and is more a research piece. 

Unfortunately, there are a number of technical issues:

The Base reproduction Number R0 is not used correctly. Ro is conceptually simple, but in fact very hard to estimate in a real population, for a real disease when there is a lack of homogeneity in transmission and contact dynamics and when the population is far from the assumed purely susceptible state. The situation is clearly much murkier in the case of information spread, where the transmission mechanism is more complex. I will skip a full discussion of the issues so as not to be a bore and avoid inaccuracies myself! My main point here is that a different term needs to be used to describe the "transmission" factor in this system. The comparison with specific disease Ro values is not only conceptually misleading, there is also no citation for the Ro numbers used for different diseases. These numbers further seem rather inaccurate and imprecise to my knowledge. This comparison should simply be avoided.

One important issue that should be clarified however: the computation of Ro per person is also hard to evaluate given that there is no clear statement in this case (there is for the global Ro calculation) whether only unique users retweeting are counted or whether the same user can contribute to the count (of one user or a number of users) multiple times. In the later case, the assumptions that the retweeter is susceptible (i.e. not infected) becomes suspect.

There is generally insufficient discussion of the limitations of the methodology. Especially in what relates to the oversimplified calculations for the "virality" of different users through retweeting. For instance, is it possible that some users appear to be retweeted simply because they mimic the behavior of other users that are heavily retweeted? In this case they are not infecting anyone themselves but would appear to. Also, a more careful characterization of the out-of-sample accounts is needed since this can introduce many limitations. For example, it is possible that the original classification misses individuals that are already ardent ISIS supporters. These individuals thus were already "infected" and can give the impression that virality of content is much higher than it really is.

Beyond the Ro and infectivity analysis, there is generally insufficient explanation and interpretation of results and of the limitations. In the conclusion the author says that their work supports the theory that extremists are using complex information strategies. Although they do not spell it out here, I believe this is in reference to the fact that different user types are revealed by the dynamic activity-connectivity maps. It is not clear to me this represents complex strategies. The classes are defined through arbitrary cutoffs and could simply be an expression of statistical variation along two dimensions. Perhaps the differences in how viral the content produced by some users would be much better explained by types along different dimensions. In my opinion, a more interesting analysis, which would address Q2 more specifically, is learning types through natural clustering (along these two dimensions or others) and quantifying how well they explain the variability in e.g. retweets.

Unless I am missing something, there seems to be a mistake in a number of the pdf plots: there are some curves (representing a specific class of users for instance), that appear to have strictly more area under them than other curves. Yet the area under all curves should be one. This is most salient in Figs. 7 and 8. How is it possible that the influential (yellow) bars in the top panel of figure 8 are taller for all Ro values? This would mean that influentials have a higher proportion of users in every Ro class! Perhaps I am missing something? All the pdf plots seem suspect to incorrect normalization or another mistake. 

Furthermore, there are no error margins or statistical significance calculations for any of the numbers computed from the data. This makes it almost impossible to gage significance of the results. 


More nit-picky issues that still need to be addressed:

Why is the related work section at the end? It would seem to belong more naturally around the introduction. It also needs to be more clearly connected to the work presented here (e.g. what limitations does the current study address?) so that a clearer assessment can be made of what the novelty is. 


The author claims that in Fig. 2 the solid blue and dashed red lines are the "typical power-law shape". I agree that these distributions are heterogeneous and with a heavy tail, but there is no indication that a power law is a particularly good fit. A more rigorous fit or wording less likely to mislead would be appropriate here. 
 
There are a number of typos, so proof reading is needed (since pages and lines are not numbered it is hard to point each one out here). However, those most confusing: 
- In the definition of /delta f, a superscript says "mix" instead of "max" .
- In section 3.4, first paragraph, the third sentence, where the notion of adoption is defined, has some missing words or incorrect grammar and therefore I cannot understand it. 

Figure 1 seems to have the wrong caption (I see no log axis etc...)

Figure 5 is not very "user friendly". The comparisons that the authors wish to draw attention to and are discussed in the text, cannot be easily made in the figure. Instead of the current presentation where the different user types are represented in different panels, the panels could for example be the three different communication statistics and  within each panel the level for each group could be presented side-by-side to enable comparisons. Or everything could be incorporated in one panel, with the comparison measurements side-by-side... Furthermore, the meaning of the different markers and symbols in the box plots should be clearly explained in the caption for those of us who forget. In this manner the reader can actually draw conclusions about to what degree the noted differences are statistically significant.

